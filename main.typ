#import "utils/gost.typ": gost, numless, indetless


#show: gost.with()


#outline()
#numless[= Введение]

Современные города сталкиваются с серьёзными вызовами в сфере управления дорожным движением. Постоянный рост количества транспортных средств и динамика перемещений граждан требуют более гибких и интеллектуальных подходов к регулированию транспортных потоков. Одним из наиболее критичных узлов в улично-дорожной сети остаются регулируемые перекрёстки, эффективность работы которых напрямую влияет на пропускную способность магистралей, уровень заторов и безопасность участников движения.

Особенно важным становится вопрос адаптации режимов светофорного управления к реальной интенсивности движения в течение суток и недели. Использование статичных режимов приводит к неоптимальному распределению времени фаз, излишним задержкам и повышенному потреблению энергии. В условиях ограниченных ресурсов появляется потребность во внедрении решений, способных повысить эффективность управления даже в оффлайн-режиме.

Развитие технологий обработки данных и элементов машинного обучения открывает возможности для создания интеллектуальных систем, способных анализировать статистику движения и предлагать обоснованные решения по оптимизации режимов работы светофоров.

Цель данного проекта — разработка интеллектуальной системы прогнозирования и планирования интенсивности движения на регулируемых перекрёстках. Система должна обеспечивать автоматизированный анализ исторических данных о транспортных потоках и формировать обоснованные рекомендации по управлению режимами светофорного регулирования.

Предлагаемая система нацелена на повышение точности в принятии решений и снижение энергопотребления за счёт более рационального распределения временных ресурсов светофорного оборудования, представляя собой шаг к созданию более устойчивой городской транспортной среды.

= Системный анализ и постановка задачи
== Изучение предметной области

Организация дорожного движения на регулируемых перекрёстках является одной из ключевых задач городского транспортного планирования и непосредственно влияет на качество жизни горожан. Эффективность функционирования светофорных объектов определяет не только пропускную способность улично-дорожной сети, но и уровень загруженности магистралей, число задержек на маршрутах, а также безопасность всех участников движения, включая пешеходов, автомобилистов и пользователей общественного транспорта.

В современном городе с высокой плотностью движения управление транспортными потоками приобретает особую значимость. Неправильно настроенные режимы светофоров приводят к образованию заторов, неравномерной нагрузке на транспортные артерии и, как следствие, к дополнительным выбросам загрязняющих веществ в атмосферу. В этой связи особое внимание уделяется вопросу оптимального распределения времени сигналов светофора в зависимости от интенсивности движения в разные периоды суток.

На практике, особенно в условиях отсутствия адаптивных светофорных систем, режимы работы светофоров задаются вручную специалистами дорожно-эксплуатационных служб. Этот процесс требует анализа больших массивов исторических данных о трафике, таких как суточные и недельные графики интенсивности движения, и значительного опыта специалистов. Обычно такой анализ осуществляется вручную — сотрудники визуально просматривают графики, определяют пиковые и непиковые интервалы, а затем на основе собственного опыта составляют расписания смены фаз, длительности циклов и пропорций зелёного времени.

Однако такой экспертный подход обладает рядом существенных недостатков. Он подвержен субъективности и не всегда обеспечивает стабильную эффективность при изменяющихся транспортных условиях. Например, строительство новых жилых кварталов, ремонт дорог или изменение маршрутов общественного транспорта могут существенно повлиять на паттерны движения, и ручная настройка может не успевать за этими изменениями. Кроме того, ручной анализ сложно масштабировать: при большом числе перекрёстков и постоянной потребности в пересмотре режимов нагрузка на специалистов становится чрезмерной.

Современные технологии анализа временных рядов, машинного обучения и визуализации данных позволяют частично или полностью автоматизировать процесс, повысив как скорость, так и объективность принимаемых решений. Особенно актуальной становится задача создания интеллектуальных систем прогнозирования и планирования интенсивности движения, которые могли бы на основе имеющихся данных выявлять закономерности трафика, формировать обоснованные рекомендации по смене режимов светофорного регулирования и, таким образом, обеспечивать эффективную работу перекрёстков даже в условиях отсутствия онлайн-адаптации.

Такие системы позволяют перейти от ручного экспертного подхода к полуавтоматизированной поддержке принятия решений, что особенно ценно в условиях ограниченного ресурса и высокой динамичности городской среды. В перспективе они могут служить промежуточным звеном между традиционным и полностью адаптивным управлением движением.

== Описание интеллектуальной системы

Интеллектуальная система прогнозирования и планирования интенсивности движения предназначена для автоматизации анализа исторических данных о транспортных потоках на регулируемых перекрёстках и формирования обоснованных рекомендаций по изменению режимов работы светофоров. Её основная функция заключается в автоматическом выделении характерных временных интервалов в течение суток или недели, в которых транспортные потоки демонстрируют существенно различающиеся характеристики. Это позволяет определять, в какие периоды необходимо использовать различные фазы и циклы светофорного регулирования, чтобы обеспечить максимальную эффективность работы перекрёстка.

Система представляет собой программное приложение с пользовательским интерфейсом, в которое инженер по организации движения может загрузить входные данные — например, статистику интенсивности по направлениям за определённый временной период (один день, рабочая неделя, совокупность аналогичных дней и т. д.). Система автоматически приводит эти данные к единому формату, обрабатывает их, анализирует структуру изменения потока и выявляет временные интервалы с различной степенью загруженности.

На выходе пользователь получает карту времени — визуализацию дня, разбитую на интервалы, для каждого из которых определены режимы светофорного управления, отражающие реальную транспортную нагрузку. Кроме того, система предоставляет сводные статистические показатели по каждому интервалу, которые можно использовать для составления проектной документации, утверждения режимов или мониторинга эффективности принятых решений. Система также поддерживает экспорт результатов и формирование отчётных материалов.

Таким образом, интеллектуальная система выступает как инструмент поддержки принятия решений в сфере организации дорожного движения. Её применение позволяет сократить зависимость от субъективных оценок, повысить качество планирования, а также масштабировать процессы анализа на большое количество объектов. Система ориентирована на оффлайн-режим прогнозирования и наиболее актуальна для использования в городах и регионах, где внедрение адаптивных светофорных систем ещё не произведено. Она может стать важным промежуточным звеном на пути к внедрению полноценных интеллектуальных транспортных систем, повышающих эффективность городской мобильности.

== Обзор существующих методов

В области прогнозирования и управления дорожным движением существует множество решений, ориентированных как на работу в реальном времени, так и на постобработку исторических данных. В данной работе основной акцент сделан на анализ исторической информации об интенсивности движения с целью последующего планирования режимов работы светофорных объектов.

Среди существующих подходов к анализу временных последовательностей интенсивности движения можно выделить две ключевые группы методов:

+ Методы кластеризации, которые позволяют объединять схожие по характеристикам участки временного ряда, выявляя повторяющиеся паттерны в трафике (например, утренние и вечерние часы пик, ночное снижение интенсивности и т.д.) @clustering;
+ Методы обнаружения точек изменений (change point detection), направленные на автоматическое выявление моментов, в которых происходит смена статистических свойств потока, таких как среднее значение или дисперсия @change-point-detection. Это позволяет делить день на интервалы с различными режимами движения без предварительного знания их структуры.

Такие методы позволяют формировать гибкие и адаптивные схемы управления движением, опираясь исключительно на накопленные эмпирические данные. Это особенно актуально в условиях, где динамическое управление в реальном времени затруднено или невозможно.

Существует также отдельный класс решений, основанных на адаптивных алгоритмах управления дорожным движением, таких как SCOOT (Split Cycle Offset Optimization Technique) и SCATS (Sydney Coordinated Adaptive Traffic System). Эти интеллектуальные транспортные системы способны в реальном времени регулировать работу светофоров на основе текущих условий на дорогах.

SCOOT, разработанная в Великобритании, функционирует на основе данных, получаемых от детекторов транспортных средств, установленных на подходах к регулируемым перекрёсткам на расстоянии примерно 40-50 метров от стоп-линии @scoot. Детекторы фиксируют прохождение автомобилей и передают информацию о количестве и скорости транспортных средств в центральную систему управления.

Алгоритм SCOOT работает по принципу непрерывной оптимизации трёх ключевых параметров светофорного регулирования. Во-первых, система корректирует длительность зелёных фаз для различных направлений движения, анализируя текущую загрузку каждого подхода к перекрёстку и перераспределяя время между фазами в зависимости от реальной потребности. Во-вторых, происходит оптимизация общего цикла светофора — система может увеличивать или уменьшать продолжительность полного цикла в зависимости от общей интенсивности движения. В-третьих, осуществляется корректировка временных смещений между соседними перекрёстками для создания "зелёной волны" и обеспечения координированного движения транспортных потоков.

SCOOT использует концепцию "степени насыщения" для каждого подхода к перекрёстку, которая рассчитывается как отношение фактического потока к пропускной способности. На основе этих данных система каждые несколько секунд принимает решения о необходимости корректировки параметров регулирования. Уникальной особенностью SCOOT является её способность объединять группы перекрёстков в регионы и оптимизировать их работу совместно, что позволяет учитывать взаимосвязь между соседними участками сети и минимизировать время задержек на всём маршруте.

Практическая эффективность системы подтверждена многочисленными внедрениями: в Лондоне SCOOT управляет более 6 000 светофоров, что позволило сократить задержки на 13%, а в Сиэтле внедрение системы на 32 перекрёстках вдоль улицы Мерсер привело к снижению задержек и улучшению надёжности движения в часы пик @scoot-london @scoot-seattle.

SCATS, разработанная в Австралии, представляет собой более сложную иерархическую систему управления, построенную по принципу распределённой архитектуры @scats. На нижнем уровне располагаются локальные контроллеры светофорных объектов, оснащённые собственными процессорами и способные функционировать автономно при потере связи с центром. Каждый контроллер анализирует данные от детекторов транспорта, установленных на всех подхода к перекрёстку, и формирует локальные стратегии управления.

Центральный компьютер системы SCATS выполняет роль координатора, получая информацию от всех подключённых перекрёстков и принимая решения о необходимости объединения или разделения светофорных объектов в координированные группы. Система способна динамически формировать "подсистемы" — группы перекрёстков, работающих синхронно для обеспечения непрерывного движения транспортных потоков. Размер и состав таких подсистем может изменяться в течение дня в зависимости от направления и интенсивности основных транспортных потоков.

Особенностью SCATS является использование концепции "степени насыщения" для каждого подхода, которая рассчитывается на основе данных о количестве прибывающих и обслуженных транспортных средств. Когда степень насыщения превышает определённые пороговые значения, система автоматически корректирует длительность зелёных фаз или общий цикл светофора. Для обеспечения приоритета общественному транспорту SCATS использует специальные детекторы, которые распознают приближение автобусов или трамваев и могут продлевать зелёную фазу или досрочно активировать её.

Дополнительным преимуществом SCATS является возможность интеграции с другими транспортными системами, включая управление въездами на автомагистрали, системы информирования участников движения и центры управления городским транспортом. Это позволяет создавать комплексные решения для управления транспортными потоками на уровне всего города или региона.

SCATS широко применяется в Австралии, Новой Зеландии, Китае, Польше и других странах @scats-countries. В Польше, например, система внедрена в 10 городах и управляет около 600 перекрёстками, демонстрируя свою адаптивность к различным условиям дорожной инфраструктуры @scats-poland. В Дублине SCATS используется для адаптивного управления движением в центре города, позволяя оперативно реагировать на изменения в трафике и обеспечивать приоритет для общественного транспорта @scats-dublin.

Однако внедрение таких адаптивных алгоритмов в широком масштабе сопряжено с рядом существенных ограничений. Прежде всего, это необходимость значительных финансовых вложений на установку детекторов, модернизацию светофорных контроллеров и создание централизованной инфраструктуры управления. Кроме того, эксплуатация подобных систем требует высокой технической подготовки персонала и сложного технического сопровождения, а их эффективность критически зависит от качества и стабильности поступающих данных от различных датчиков и устройств.

В текущих условиях большинство городов и населённых пунктов региона не располагают необходимой инфраструктурой для реализации адаптивного управления в реальном времени. На территории Беларуси отсутствует широкомасштабное внедрение подобных систем — большинство светофорных объектов функционируют по фиксированным расписаниям, заданным вручную, без возможности динамической адаптации к текущим условиям на дорогах. Лишь в рамках отдельных проектов трансграничного сотрудничества, например в городе Брест, были реконструированы семь перекрёстков с установкой элементов адаптивной системы управления движением.

Учитывая изложенные ограничения, подход на основе анализа исторических данных представляется наиболее целесообразным и применимым в существующих условиях. Он позволяет повысить эффективность организации движения без необходимости радикальной перестройки инфраструктуры и значительных капитальных вложений.

В связи с этим далее будут рассмотрены два класса методов, наиболее подходящих для решения поставленной задачи: методы кластеризации и алгоритмы обнаружения точек изменений. Эти подходы позволяют автоматически структурировать временные ряды интенсивности движения и формировать интервалы для назначения различных режимов светофорного регулирования на основе накопленных эмпирических данных.

=== Методы кластеризации

Кластеризационные методы представляют собой важный класс алгоритмов, применяемых для группировки объектов на основе их сходства. В контексте анализа временных рядов интенсивности движения они позволяют автоматически выявлять участки с однородными характеристиками потока — например, часы пик, периоды низкой загрузки или нестандартные аномальные интервалы.

Ключевая идея кластеризации заключается в том, чтобы разделить данные на непересекающиеся подмножества (кластеры или сегменты), внутри которых объекты (вектора интенсивностей по каждому из направлений) схожи между собой по выбранным признакам, а между кластерами — различаются.

Ниже перечислены и кратко охарактеризованы основные подходы к кластеризации, применимые для анализа временных рядов интенсивности движения:

// Кластеризация на основе экспертных правил

+ Кластеризация на основе экспертных правил -- кластеризация, которая представляет собой детерминированный метод группировки объектов, при котором принадлежность к кластерам определяется заранее сформулированными логическими или математическими условиями. Эти условия разрабатываются экспертами предметной области и отражают известные закономерности или структуры в данных. В отличие от статистических или машинно-обучаемых подходов, такой метод не требует предварительного обучения и обеспечивает высокую интерпретируемость результатов. Примеры правил могут включать логические выражения вида «если признак A больше признака B и меньше признака C, то отнести объект к кластеру X». #linebreak() Несмотря на высокую интерпретируемость и прозрачность, кластеризация на основе экспертных правил обладает рядом существенных ограничений. Основным недостатком является необходимость ручной разработки правил для каждого случая, что требует значительных временных и экспертных ресурсов. По мере увеличения числа признаков и возможных состояний системы сложность правил возрастает, что затрудняет масштабирование метода. Кроме того, при изменении количества требуемых кластеров необходимо заново формулировать условия распределения, так как они, как правило, специфичны для заданного числа групп. Это делает метод менее гибким по сравнению с алгоритмами, автоматически адаптирующимися под структуру данных.

// Пороговая кластеризация

+ Пороговая кластеризация -- это разновидность детерминированной кластеризации, в которой разделение объектов на кластеры осуществляется на основе сравнения признаков с заранее установленными пороговыми значениями. Каждый кластер определяется диапазоном значений одного или нескольких признаков. Например, если значение параметра находится в интервале $[T_1, T_2]$, объект попадает в один кластер; при значении ниже $T_1$ -- в другой и т.д. Такой подход широко используется в задачах с чётко определёнными граничными условиями и хорошо подходит для систем, требующих прозрачности, интерпретируемости и простоты внедрения. #linebreak() Пороговая кластеризация, хотя и проста в реализации, чувствительна к выбросам и шуму в данных. Небольшие отклонения значений признаков, особенно вблизи пороговых границ, могут приводить к резкой смене кластерной принадлежности, что снижает устойчивость метода. Кроме того, выбор оптимальных порогов, как правило, осуществляется вручную или эмпирически, что делает метод зависимым от качества предварительного анализа и может приводить к потере обобщающей способности при изменении структуры данных. Также данный подход плохо справляется с высокоразмерными и слабо разделимыми данными, где пороговое разделение становится неэффективным.

// k-means

+ Алгоритм k-means (k-средних) является одним из наиболее широко используемых методов кластеризации благодаря своей простоте и эффективности @k-means. Он направлен на минимизацию внутрикластерной дисперсии, что делает его особенно полезным в задачах, где требуется компактность кластеров. Алгоритм итеративно распределяет объекты по k кластерам, обновляя центроиды до достижения сходимости. Его преимущества включают быструю сходимость, масштабируемость для больших наборов данных и легкость реализации, что делает его популярным выбором в различных областях анализа данных. #linebreak() Однако, несмотря на свои достоинства, k-means имеет ряд ограничений, которые делают его не подходящим для задач с определенными характеристиками данных. Алгоритм предполагает, что кластеры имеют сферическую форму и схожий размер, что не соответствует структурам, расположенным вдоль временной оси или имеющим сложные геометрические формы. Кроме того, k-means чувствителен к выбросам: аномальные значения могут существенно сместить центроиды, искажая результаты кластеризации. Также, хотя алгоритму задается количество кластеров k, на практике он может не обнаружить заданное число кластеров, особенно если данные не четко разделены, что приводит к объединению близких кластеров и снижению точности кластеризации.

// DBSCAN

+ Алгоритм DBSCAN представляет собой метод кластеризации, основанный на анализе плотности данных @DBSCAN. Его принцип заключается в объединении объектов в кластеры, если они расположены достаточно близко друг к другу и образуют плотную область в пространстве признаков. При этом необходимо задавать два параметра: $epsilon$ -- радиус окрестности, и $M i n P t s$ -- минимальное количество точек в этой окрестности. Основными преимуществами DBSCAN являются способность выявлять кластеры произвольной формы, устойчивость к выбросам и автоматическое определение количества кластеров, что делает алгоритм особенно полезным при наличии шумов или неоднородных структур в данных.#linebreak() Несмотря на преимущества DBSCAN, его ключевая особенность -- отсутствие необходимости заранее задавать количество кластеров -- в ряде случаев может оборачиваться недостатком. В частности, если в задаче требуется получение строго заданного числа кластеров, DBSCAN не предоставляет такого механизма управления. Более того, поскольку алгоритм основан на плотностной модели, он плохо работает в условиях, когда данные равномерно или чрезмерно плотно распределены. В подобных ситуациях алгоритм либо объединяет слишком много объектов в один кластер, либо не может корректно отделить кластеры друг от друга, что приводит к потерям в точности сегментации и делает его неприменимым в задачах с высокой плотностью и временной структурой данных, как в рассматриваемом случае.

// Gaussian Mixture Model, GMM

+ Алгоритм кластеризации на основе гауссовой смеси (Gaussian Mixture Model, GMM) предполагает, что данные сгенерированы из комбинации нескольких нормальных (гауссовских) распределений с различными параметрами @gmm. Модель оценивает вероятность принадлежности каждой точки к каждому кластеру, что позволяет формировать мягкое (вероятностное) разбиение данных. Основой метода является алгоритм ожидания-максимизации (Expectation-Maximization, EM), который итеративно уточняет параметры распределений (средние, дисперсии, веса), максимизируя правдоподобие наблюдаемых данных. GMM позволяет моделировать эллипсоидные формы кластеров, хорошо работает с перекрывающимися группами и часто используется в задачах, где требуется более гибкий подход по сравнению с k-means. #linebreak() Тем не менее, применение гауссовой смеси предполагает, что данные подчиняются нормальному закону распределения, что не всегда соответствует действительности. В рамках рассматриваемой задачи распределения признаков существенно отклоняются от нормального и обладают дискретной, асимметричной структурой, что делает использование GMM некорректным. Модель плохо справляется с данными, близкими к распределению Пуассона, а также может давать некорректные границы кластеров при наличии выбросов или неоднородной плотности. Несмотря на популярность GMM в задачах распознавания и сегментации, её ограниченность по типу применимых распределений не позволяет эффективно использовать её в данной предметной области.

// Poisson Mixture Model, PMM

+ Пуассоновская смесь (Poisson Mixture Model, PMM) представляет собой вероятностную модель, аналогичную гауссовской смеси, но предполагает, что данные подчиняются распределению Пуассона @pmm. Этот тип кластеризации особенно хорошо подходит для моделирования счётных величин, частотных признаков и дискретных событий, что делает его применимым к задачам анализа временных рядов, журналов событий и других типов данных, где значения представляют собой количества. Как и в GMM, используется EM-алгоритм для оценки параметров смеси и вероятностного распределения объектов по кластерам. Основное преимущество метода -- его адаптивность к дискретным распределениям и высокая интерпретируемость параметров кластеров в терминах интенсивности ($lambda$) пуассоновских процессов. #linebreak() Однако использование пуассоновской смеси также связано с рядом ограничений. Во-первых, модель предполагает, что признаки подчиняются именно пуассоновскому распределению, что ограничивает её универсальность. Во-вторых, PMM чувствительна к мультиколлинеарности и выбросам, а также может испытывать трудности при разделении кластеров с близкими значениями интенсивности. Кроме того, в отличие от GMM, пуассоновская смесь хуже моделирует непрерывные и симметричные данные. Несмотря на это, в рассматриваемой задаче, где наблюдаются счётные значения и асимметричные распределения, модель пуассоновской смеси представляет собой более адекватный подход, чем гауссовская альтернатива.

// Агломеративная кластеризация

+ Агломеративная кластеризация относится к иерархическим методам кластеризации, при которых построение кластеров происходит снизу вверх: изначально каждый объект считается отдельным кластером, а затем кластеры последовательно объединяются в соответствии с выбранным критерием схожести. Одним из наиболее эффективных подходов является использование метода Уорда (Ward’s linkage), основанного на минимизации приращения внутрикластерной дисперсии при каждом объединении @agglomerative. Это делает его особенно подходящим для задач, в которых важно не только сохранить близкие объекты вместе, но и обеспечить компактность и чёткую границу между кластерами. Метод Уорда обеспечивает более сбалансированное разбиение по сравнению с другими иерархическими подходами и хорошо подходит для структур с кластерной компактностью и раздельностью.

// Алгоритм FINCH (First Integer Neighbor Clustering Hierarchy)

+ FINCH -- это агломеративный алгоритм кластеризации, основанный на связях первого ближайшего соседа. На каждой итерации алгоритм объединяет точки в кластеры, если они имеют общих ближайших соседей, и тем самым формирует иерархическую структуру кластеров @finch. Он не требует предварительной настройки гиперпараметров, таких как количество кластеров или радиус поиска, что делает его особенно удобным при работе с неизвестной структурой данных. При этом, несмотря на отсутствие параметров, FINCH позволяет контролировать итоговое число кластеров: поскольку он агломеративен, можно остановить процесс на нужной итерации, когда достигается желаемое количество кластеров. Это делает его гибким инструментом для практических задач. #linebreak() Однако FINCH не оптимизирует расстояние между кластерами и не стремится к максимальной межкластерной разницы. В результате, кластеры могут располагаться близко друг к другу или быть слабо различимыми. Это особенно критично в задачах, где важна чёткая разнесённость кластеров, например, при формировании дискретных классов поведения или состояний. Кроме того, использование лишь ближайшего соседа делает алгоритм чувствительным к локальным структурам и выбросам, что может снижать устойчивость результатов на сложных или временно-коррелированных данных.

// Алгоритм TW-FINCH (Temporally-Weighted FINCH)

+ TW-FINCH представляет собой модификацию FINCH, предназначенную для работы с временными данными. Основное отличие заключается во введении временных весов, позволяющих учитывать порядок появления объектов. Это особенно полезно при кластеризации временных рядов, событийных логов или видеофреймов, где последовательность имеет значение @tw-finch. TW-FINCH сохраняет все достоинства базовой версии: он не требует задания числа кластеров или других параметров, но благодаря агломеративной природе может быть остановлен на нужном уровне иерархии, что позволяет получить заранее заданное число кластеров без перебора параметров. #linebreak() Тем не менее, как и оригинальный FINCH, TW-FINCH не направлен на максимизацию расстояния между кластерами и не обеспечивает формирование максимально разнесённых групп. Это может быть существенным недостатком в задачах, где важна интерпретируемость и отчётливость кластеров. Кроме того, качество кластеризации в TW-FINCH зависит от корректного задания временных весов: при их неудачном выборе может ухудшиться точность, особенно в ситуациях, когда временной порядок не коррелирует с кластерной структурой.

Несмотря на разнообразие методов и их способность выявлять кластеры с высокой межкластерной разницей и низкой внутрикластерной дисперсией, включая особенно эффективный в условиях временной структуры алгоритм TW-FINCH, большинство описанных подходов имеют один общий и серьёзный недостаток. Они не предусматривают прямого механизма ограничения размера кластеров, особенно по временной оси. В задачах, где необходимо контролировать длительность сегментов или обеспечить равномерное распределение объектов между кластерами, такие алгоритмы оказываются либо неприменимыми, либо требуют сложных обходных решений. Более того, многие из них не позволяют явно задать желаемое число кластеров, что критично в прикладных сценариях с фиксированными требованиями к выходной структуре. В этом контексте методы кластеризации оказываются ограниченно пригодными для задач планирования и прогнозирования интенсивности движения, где важно не только выявление структур, но и соблюдение чётких ограничений по длительности и количеству временных интервалов.

=== Методы обнаружения точек изменений

Методы обнаружения точек изменений представляют собой класс алгоритмов, предназначенных для автоматического выявления моментов времени, в которых происходят существенные изменения статистических свойств временного ряда. В задаче анализа интенсивности движения такие изменения могут соответствовать переходам между различными режимами трафика — например, началом утреннего часа пик, снижением нагрузки в обеденный период или резким спадом движения в ночное время.

Основная идея данных методов заключается в том, чтобы разложить временной ряд на последовательность сегментов, внутри которых характеристики потока (такие как среднее значение, дисперсия, частотные свойства и т. д.) сохраняются относительно стабильными, а между сегментами происходят статистически значимые сдвиги. Это позволяет более точно выделять границы между интервалами, требующими различных подходов к управлению движением.

Подобные алгоритмы особенно полезны в ситуациях, когда структура временного ряда заранее неизвестна, и необходим автоматический способ сегментации на основе данных. Они хорошо сочетаются с последующим анализом, включая планирование режимов светофорного регулирования.

В этот обзор включены также подходы, которые не относятся строго к классическим методам обнаружения точек изменений, такие как ClaSP и Ptr-Net. Несмотря на это, их механизмы направлены на автоматическое разбиение временного ряда на однородные участки, что делает их функционально сопоставимыми с методами сегментации. Эти алгоритмы широко используются на практике для идентификации границ между различными режимами в данных и поэтому уместны в контексте поставленной задачи.

Ниже перечислены и кратко охарактеризованы основные подходы, применимые для анализа временных рядов интенсивности движения:

// ClaSP (Classification Score Profile)

+ ClaSP (Closed Sequential Patterns) — это современный метод сегментации временных рядов, основанный на самообучении. Он не требует предварительной разметки данных и способен выявлять точки изменений без необходимости задания количества сегментов или других гиперпараметров @clasp2023. ClaSP иерархически разделяет временной ряд на две части, определяя точку разделения путём обучения бинарного классификатора для каждой возможной точки и выбора той, которая обеспечивает наилучшее различие между сегментами. Этот процесс повторяется рекурсивно, что позволяет строить иерархическую структуру сегментов. В экспериментальной оценке на 107 датасетах алгоритм продемонстрировал превосходство по точности над другими методами сегментации, что подтверждает его статус state-of-the-art в своей категории @sota-clasp. #linebreak() Однако, несмотря на высокую точность, ClaSP имеет ряд ограничений. Он не предоставляет прямого механизма управления количеством сегментов, что затрудняет его использование в задачах, где необходимо строго фиксированное число кластеров. Более того, алгоритм ориентирован на выявление резких изменений, что делает его менее пригодным для данных с плавными или неявными переходами. Например, ClaSP плохо справляется с анализом временных рядов интенсивности транспортного потока на перекрёстках, где изменения происходят постепенно, а различия между режимами движения могут быть выражены слабо и размыто. Кроме того, высокая чувствительность к шуму и выбросам требует дополнительной фильтрации данных, особенно при работе с реальными сенсорными измерениями. Также стоит отметить, что эффективность ClaSP резко снижается при работе с короткими временными рядами: из-за малого количества доступных шагов модель не может построить достаточное количество обучающих выборок для классификации, что приводит к неустойчивым и малонадежным результатам сегментации.

// Алгоритм Pointer Networks (Ptr-Net)

+ Pointer Networks (Ptr-Net) представляют собой нейросетевую архитектуру, разработанную для решения задач с переменным размером выходных данных, таких как комбинаторные оптимизационные задачи. В отличие от традиционных моделей sequence-to-sequence, Ptr-Net использует механизм внимания не для генерации новых элементов, а для указания на элементы входной последовательности, тем самым формируя выходную последовательность из индексов входных данных @ptr-net. Это делает Ptr-Net особенно эффективными в задачах, где необходимо выбирать позиции в последовательности, например, при сегментации временных рядов, где требуется определить точки разделения. Архитектура Ptr-Net позволяет обрабатывать входные последовательности переменной длины и генерировать выходы соответствующей длины, что обеспечивает гибкость в различных приложениях. #linebreak() Однако, несмотря на свои преимущества, применение Ptr-Net в задачах сегментации временных рядов имеет определённые ограничения. Во-первых, модель ориентирована на точное определение позиций сегментов, что может быть неэффективно при наличии плавных или неявных переходов в данных. Во-вторых, Ptr-Net чувствительны к шуму и выбросам, что может снижать точность сегментации в реальных данных, таких как измерения интенсивности движения на перекрёстках, где изменения происходят постепенно и могут быть размытыми. Кроме того, обучение Ptr-Net требует большого объёма размеченных данных, что может быть затруднительно в условиях ограниченных ресурсов.

// Kernel Change Detection (KernelCPD)

+ Kernel Change Detection (KernelCPD) — это метод обнаружения точек перемены, основанный на использовании ядровых функций для выявления изменений в распределении данных @kernelcpd. Вместо того чтобы полагаться на простые статистики, такие как среднее или дисперсия, алгоритм сопоставляет сегменты временного ряда в преобразованном пространстве признаков, что позволяет выявлять сложные и нелинейные изменения структуры данных. Использование ядер, например, гауссового, позволяет "увидеть" переходы между состояниями, которые были бы незаметны при линейной обработке. Благодаря этому KernelCPD особенно полезен для сложных или нестационарных временных рядов, где перемены не выражены явно. #linebreak() Тем не менее, данный подход имеет ряд ограничений. Прежде всего, KernelCPD отличается высокой вычислительной затратностью, особенно при использовании сложных ядер и больших объёмов данных. Кроме того, он требует настройки параметров ядра, таких как ширина, что усложняет применение без априорных знаний о данных. Особенно важно отметить, что при работе с короткими временными рядами (в том числе с небольшим числом наблюдений между возможными точками перемены) алгоритм оказывается неэффективным: он может либо не обнаружить изменения вовсе, либо зафиксировать их в произвольных местах, не отражающих реальную структуру данных. Таким образом, несмотря на свою гибкость, KernelCPD хуже всего работает в условиях ограниченного количества данных и высокой чувствительности к шуму.

// Binary Segmentation (Binseg)

+ Алгоритм Binary Segmentation (бинарная сегментация) представляет собой один из наиболее простых и интуитивно понятных методов обнаружения точек перемены в временных рядах @binseg. Он реализует жадную стратегию разбиения: на каждой итерации алгоритм ищет одну наиболее выраженную точку перемены во всей последовательности, разделяет её на два сегмента и рекурсивно применяет тот же подход к каждой из полученных частей. Такой подход обеспечивает высокую вычислительную эффективность, особенно при небольшом числе предполагаемых точек перемены. Благодаря своей простоте, Binseg широко используется как базовый метод сегментации и часто применяется для быстрой предварительной разметки данных. #linebreak() Однако жадная природа Binary Segmentation делает его чувствительным к ошибкам на ранних этапах разбиения. Если на начальных итерациях была выбрана ложная точка перемены, это может повлиять на всю дальнейшую структуру сегментов. Кроме того, алгоритм не оптимизирует глобальную функцию стоимости и не пересматривает уже выполненные разбиения, из-за чего итоговая сегментация может быть далека от оптимальной. В задачах, где данные содержат шум, неявные или многочисленные точки перехода между режимами (как, например, в данных дорожной интенсивности), Binseg часто формирует сегменты одинаковой длины, не адаптируясь к реальной структуре данных. Это делает его менее подходящим для данного случая.

// Bottom-Up Segmentation

+ Алгоритм Bottom-Up Segmentation представляет собой иерархический метод обнаружения точек перемены, который реализует подход снизу вверх @bottomup. В отличие от бинарной сегментации, начинающейся с целого ряда, Bottom-Up изначально разбивает временной ряд на множество мелких равномерных сегментов. Далее происходит итеративное объединение соседних сегментов на основе заданной метрики схожести — например, минимизации прироста внутрикластерной дисперсии. Такой подход позволяет постепенно формировать более крупные и устойчивые сегменты, адаптируясь к локальной структуре данных. Преимущество Bottom-Up Segmentation заключается в его гибкости и способности выявлять как крупные, так и мелкие изменения в данных. Метод не требует предварительного задания числа сегментов, а остановку объединения можно регулировать на основе критерия слияния или ошибки аппроксимации. Это делает его удобным для предварительного анализа временных рядов, особенно в ситуациях с неоднородными интервалами между точками перемены. #linebreak() Тем не менее, метод обладает рядом ограничений. Он чувствителен к выбору начального размера сегмента — слишком мелкое разбиение может привести к высокому числу ложных объединений, тогда как слишком крупное — к пропуску важных локальных изменений. Также, поскольку объединение происходит итеративно и на основе локального критерия, результат может не соответствовать глобально оптимальному разбиению. Алгоритм может быть особенно подвержен ошибкам в присутствии шума или выбросов.

// Window Sliding Segmentation (Сегментация с использованием скользящего окна)

+ Window Sliding Segmentation (WSS) — это простой и интуитивно понятный алгоритм обнаружения точек перемены, основанный на анализе временного ряда с помощью скользящего окна фиксированной длины @window. Суть метода заключается в том, что по ходу временного ряда сравниваются статистические характеристики двух соседних окон — например, средние значения, дисперсии или другие метрики. Если различие между окнами превышает заданный порог, фиксируется точка перемены. Такой подход позволяет эффективно выявлять локальные изменения в данных, особенно когда они происходят резко и контрастно. Алгоритм обладает низкой вычислительной сложностью, может работать в реальном времени и легко интерпретируется. #linebreak() Однако Window Sliding Segmentation имеет ряд ограничений. Прежде всего, чувствительность алгоритма сильно зависит от размера окна: слишком маленькое окно делает метод склонным к ложным срабатываниям на шум, в то время как слишком большое — сглаживает изменения и может привести к пропуску важных сегментов. Также метод предполагает, что точки перемены выражены явно — при наличии плавных, размытых или неявных переходов (что типично для реальных данных, например, при анализе транспортных потоков) эффективность WSS заметно снижается. Алгоритм не адаптируется к структуре данных и требует ручной настройки порогов и размеров окна, что ограничивает его применение в задачах с высокой вариативностью временного поведения.

// Алгоритм PELT (Pruned Exact Linear Time)

+ PELT — это один из наиболее популярных алгоритмов для обнаружения точек перемены в временных рядах, представленный в библиотеке ruptures. Его ключевая особенность — это возможность выполнять глобальную оптимизацию функции стоимости при линейной или почти линейной временной сложности @pelt. В основе метода лежит динамическое программирование с использованием эвристики "обрезки" (pruning), которая позволяет исключать промежуточные решения, не способные привести к глобальному минимуму. Это делает PELT особенно привлекательным для анализа длинных временных рядов, где необходима высокая эффективность без ущерба для точности. Алгоритм работает с различными функциями стоимости, включая L2, L1, и модели на основе вероятностей. #linebreak() Одним из главных преимуществ PELT является его способность автоматически определять количество точек перемены, минимизируя функцию стоимости с добавлением штрафа (например, AIC или BIC). Однако эта гибкость одновременно является и слабым местом: качество сегментации чувствительно к выбору штрафного параметра. Если он задан некорректно, алгоритм может либо пропустить значимые изменения (при высоком штрафе), либо зафиксировать слишком много ложных срабатываний (при низком). Кроме того, при наличии шума или медленных, неявных переходов в данных (например, в задачах с интенсивностью трафика или плавными изменениями поведения) PELT может давать нестабильные или неинтерпретируемые результаты.

// Диначеское программирование (Dynamic Programming)

+ Алгоритм динамического программирования в контексте сегментации временных рядов реализует подход глобальной оптимизации: он ищет такое множество точек перемены, которое минимизирует суммарную функцию стоимости на всём ряде @dynp. В отличие от жадных или иерархических методов (таких как Binary Segmentation или Bottom-Up), этот метод перебирает все возможные разбиения с учётом заданного количества изменений и выбирает оптимальное. Алгоритм гибко адаптируется к различным функциям потерь. В результате он позволяет получить наиболее точные и сбалансированные границы между сегментами. Одним из ключевых преимуществ Dynamic Programming перед другими методами является то, что он не страдает от ошибок локальной оптимизации. Например, методы Binary Segmentation или Bottom-Up могут допускать неточности на ранних этапах, которые затем невозможно исправить. В то же время алгоритмы вроде PELT или KernelCPD зависят от параметров регуляризации и чувствительны к шуму. Dynamic Programming же гарантирует нахождение оптимального разбиения (при заданном числе сегментов), что делает его особенно эффективным в задачах, где критична точность сегментации — например, при структурном анализе данных, выявлении смены режимов или фаз. #linebreak() Тем не менее, несмотря на точность и детерминированность, метод имеет и ряд ограничений. Во-первых, он требует явной рекурсивной формулировки задачи, что делает его плохо применимым при сложных, недифференцируемых или неразложимых функциях стоимости. Во-вторых, добавление нестандартных ограничений (например, минимальная длина сегмента, исключение разбиения внутри определённых интервалов или включение семантических условий) часто нарушает рекурсивную структуру и затрудняет применение метода. Кроме того, алгоритм слабо приспособлен к многокритериальной оптимизации — в отличие от эвристических методов, таких как генетические алгоритмы, он не позволяет легко учитывать сразу несколько факторов качества. Таким образом, при всей своей точности, подход на основе динамического программирования лучше всего работает в чётко формализованных задачах с простой и гладкой функцией потерь, и теряет универсальность в более сложных или гибких сценариях анализа временных рядов.

Таким образом, несмотря на разнообразие подходов и теоретическую привлекательность ряда алгоритмов, большинство методов обнаружения точек изменений сталкиваются с теми же ограничениями, что и методы кластеризации. В частности, они не обеспечивают прямого управления длиной и числом сегментов, что критически важно в прикладных задачах планирования, где требуется предсказуемая и управляемая структура выходных данных. Более того, в отличие от кластеризации, эти методы часто не гарантируют высокой межкластерной разницы и низкой внутрикластерной дисперсии: сегменты могут отличаться по длине, статистическим характеристикам и не иметь чёткой интерпретации, особенно в условиях шума и плавных переходов между режимами.

Наиболее близким к практическим требованиям алгоритмом является метод динамического программирования, поскольку он позволяет задать фиксированное количество сегментов и обеспечивает глобально оптимальное разбиение по функции стоимости. Однако он также не решает задачу в полном объёме, поскольку не позволяет одновременно учитывать все необходимые требования: максимизацию различий между сегментами, минимизацию внутрисегментной дисперсии, а также наличие жёстких ограничений как на количество, так и на длину сегментов.

== Обоснование необходимости создания интеллектуальной системы

Анализ текущей ситуации в области организации дорожного движения на регулируемых перекрёстках выявляет ряд существенных проблем, которые обосновывают необходимость разработки специализированной интеллектуальной системы:

+ Высокая степень субъективности при разработке режимов работы светофоров — процесс определения временных интервалов осуществляется преимущественно на основе экспертных оценок и личного опыта специалистов, что приводит к непоследовательности решений.

+ Значительные временные затраты на анализ данных — ручная обработка больших объёмов информации об интенсивности движения требует существенных трудозатрат инженеров дорожных служб.

+ Ограниченная масштабируемость существующих подходов — по мере роста числа перекрёстков традиционные методы ручного планирования становятся неэффективными.

+ Недостаточная оперативность реакции на изменения городской инфраструктуры, сезонные колебания интенсивности и другие факторы, требующие регулярного пересмотра режимов работы светофоров.

+ Отсутствие единой методологии — различные специалисты используют разные критерии и подходы к сегментации данных о трафике, что затрудняет оценку эффективности принимаемых решений.

+ Сложность учёта долгосрочных тенденций — человеческий анализ затрудняется при необходимости выявления долгосрочных трендов и сезонных паттернов.

+ Неадаптированность существующих алгоритмов к специфике транспортных данных — большинство методов кластеризации и обнаружения точек изменений не предоставляют механизма для прямого задания желаемого числа временных интервалов и их минимальной/максимальной длительности, а также недостаточно точны. 

Необходимость создания специализированной интеллектуальной системы продиктована потребностью в инструменте, способном автоматизировать процесс определения оптимальных временных интервалов для применения различных режимов управления движением. Такая система должна учитывать технические ограничения, включая минимально допустимую длительность фаз светофорного цикла, обеспечивать существенные различия между соседними интервалами для обоснованности переходов между режимами, а также минимизировать внутреннюю вариативность данных в пределах одного интервала для повышения стабильности работы светофорных объектов. Важными характеристиками являются высокая интерпретируемость результатов для специалистов, устойчивость к шумам и аномалиям, характерным для данных транспортных детекторов, а также способность к масштабированию, позволяющая эффективно обрабатывать информацию для большого количества перекрёстков и различных временных периодов.

Внедрение интеллектуальной системы также обеспечит:

- Экономическую эффективность — оптимизация работы светофоров даст значительную экономию за счёт сокращения заторов и снижения расхода топлива;
- Снижение экологической нагрузки — сокращение простоев транспорта приведёт к уменьшению выбросов выхлопных газов;
- Повышение безопасности движения — оптимальные режимы работы светофоров снизят вероятность аварийных ситуаций.

== Постановка задачи

Целью данного проекта является разработка интеллектуальной системы прогнозирования и планирования интенсивности движения, предназначенной для поддержки принятия решений при организации светофорного регулирования на городских перекрёстках. Система должна обеспечивать автоматическое выявление характерных закономерностей транспортных потоков и формирование обоснованных рекомендаций по управлению движением на основе анализа и прогнозов временных рядов.

Основная задача системы заключается в объективной оценке текущих и будущих уровней транспортной нагрузки и в определении оптимальных временных интервалов, в течение которых следует применять различные режимы светофорного регулирования. Система должна учитывать реальное распределение интенсивности движения в разные периоды суток и недели, включая особенности будних, выходных и праздничных дней, а также автоматически выявлять временные интервалы, в течение которых целесообразно применять различные режимы светофорного регулирования, исходя из характерных паттернов движения.

Разрабатываемая система должна представлять собой приложение для автоматизированного анализа транспортных данных, в которое пользователь загружает информацию об интенсивности движения (например, в формате CSV или PDF), после чего система обрабатывает эти данные, выявляет характерные временные интервалы с разной транспортной нагрузкой и формирует карты времени с рекомендациями по режимам светофорного регулирования. В результате пользователь получает наглядную визуализацию суточной и недельной динамики движения, статистику по каждому интервалу, а также обоснованные предложения по переключению режимов светофора в конкретные временнные промежутки.

Интеллектуальная система прогнозирования и планирования интенсивности движения должна обеспечивать:

+ Поддержка загрузки и валидации входных данных в форматах CSV и PDF.

+ Преобразование и унификация данных, приведение их к единой структуре временных рядов.

+ Реализация механизмов фильтрации, агрегации и заполнения пропусков.

+ Автоматический анализ интенсивности движения по направлениям на перекрестке.

+ Выделение оптимальных временных интервалов для режимов светофорного регулирования.

+ Расчёт статистических показателей для каждого временного сегмента и их вывод.

+ Визуализация карт времени и суточной интенсивности.

+ Реализация серверной части с REST API для взаимодействия с пользовательским интерфейсом.

+ Пользовательский интерфейс для загрузки данных, контроля статуса и экспорта результатов.

Разработка интеллектуальной системы прогнозирования и планирования интенсивности движения позволит создать надёжный инструмент для автоматизированного анализа транспортных потоков и формирования обоснованных рекомендаций по управлению светофорным регулированием. Учитывая временные закономерности и реальные характеристики движения, такая система обеспечит высокую точность планирования, адаптацию к изменениям в трафике и снижение трудозатрат специалистов. Таким образом, интеллектуальная система прогнозирования и планирования интенсивности движения станет важным звеном в повышении эффективности и устойчивости управления городским транспортом.

= Проектирование системы

== Архитектура системы

Интеллектуальная система прогнозирования и планирования интенсивности движения спроектирована с использованием модульной архитектуры, что обеспечивает гибкость, масштабируемость и возможность независимой разработки и тестирования компонентов.
Система состоит из нескольких взаимосвязанных модулей, каждый из которых выполняет строго определённую функцию.

Схема взаимодействия модулей в системе представлена на рисунке @general-system-architecture.
#figure(
    image("схемы/структурная_схема_системы.png", width: 70%), // TODO заменить на реальную схему
    caption: "Схема взаимодействия модулей в системе"
) <general-system-architecture>

Ниже приведено описание ключевых модулей, входящих в состав системы:

- Модуль графического интерфейса: обеспечивает взаимодействие пользователя с системой. Отвечает за загрузку исходных данных, настройку параметров анализа, визуализацию процесса обработки и отображение конечных результатов в удобном и наглядном виде.

- Серверная часть системы: выполняет функции координации и обработки данных. В её состав входят следующие функциональные модули:

    - Модуль обработки входных данных: реализует функции парсинга и предобработки информации, поступающей от пользователя. Поддерживает загрузку данных в различных форматах (например, CSV, JSON), выполняет их очистку, нормализацию, временное упорядочивание и приведение к унифицированной структуре временных рядов, пригодных для последующего анализа.

    - Модуль анализа трафика: содержит основную вычислительную логику системы. Выполняет сегментацию временных рядов интенсивности движения, идентификацию устойчивых паттернов, определение типовых временных зон, а также формирует рекомендации по оптимизации режимов светофорного регулирования на основе выявленных закономерностей.

    - Модуль формирования отчётных данных: отвечает за визуализацию и представление результатов анализа. Формирует график интенсивности движения с разбивкой на сегменты, а также таблицу отчёта, включающую ключевые метрики и параметры, выявленные в процессе анализа. Обеспечивает подготовку структурированных данных для вывода в интерфейсе и последующего экспорта.

Взаимодействие между модулями организовано следующим образом: пользователь через графический интерфейс инициирует необходимые процессы, направляя соответствующие запросы на сервер. Серверная часть обрабатывает запросы, передаёт данные в модуль обработки входных данных, затем в модуль анализа трафика, а полученные результаты направляет в модуль формирования отчётных данных. После этого готовая информация возвращается в графический интерфейс для визуализации и экспорта.

Такое распределение обязанностей между модулями способствует высокой устойчивости системы, облегчает масштабирование и обновление отдельных компонентов, а также обеспечивает прозрачность выполнения всех этапов анализа трафика.

== Проектирование модуля графического интерфейса

Пользовательский интерфейс системы может быть реализован с использованием различных платформ: десктопных приложений, мобильных приложений и веб-страниц. Наиболее целесообразным решением является веб-интерфейс, поскольку он обеспечивает платформонезависимость, универсальность запуска через любой современный браузер и не требует установки дополнительного программного обеспечения. Такой подход упрощает доступ пользователей к системе, расширяя охват и облегчая распространение. В основе создания веб-интерфейсов лежат три ключевых технологии: HTML, CSS и JavaScript.

HTML, или язык гипертекстовой разметки, выполняет роль каркаса веб-страницы, определяя её структуру @html. С его помощью указываются местоположения элементов интерфейса — текстов, заголовков, изображений, интерактивных компонентов и других визуальных блоков.

CSS, или каскадные таблицы стилей, отвечает за оформление страницы. С его помощью задаются шрифты, цвета, размеры, отступы, выравнивание и другие параметры отображения элементов @css. Разделение структуры (HTML) и стиля (CSS) позволяет упростить модификацию внешнего вида и поддержание кода в актуальном состоянии. Иерархическая система стилей делает их применение гибким и масштабируемым как к отдельным элементам, так и к их группам.

JavaScript — это язык программирования, обеспечивающий интерактивность интерфейса @javascript. Он позволяет реагировать на действия пользователя, изменять содержимое страницы без её перезагрузки, обмениваться данными с сервером и реализовывать визуальные эффекты и анимации. Благодаря своей универсальности и поддержке различных парадигм программирования, JavaScript широко используется как на клиентской, так и на серверной стороне, включая использование через платформу Node.js.

Для реализации графического интерфейса было принято решение отказаться от использования фреймворков, таких как React, Vue.js, Angular или Next.js. Это обусловлено простотой задачи: интерфейс предназначен для загрузки и обработки данных, и использование чистого HTML, CSS и JavaScript полностью соответствует требованиям. Такой подход снижает сложность архитектуры, исключает зависимость от сторонних библиотек, упрощает сопровождение проекта и обеспечивает максимальную гибкость и совместимость.

Организация пользовательского взаимодействия должна строиться как последовательность логически связанных этапов. Каждый следующий шаг должен становиться доступным только после корректного завершения предыдущего, что позволяет пользователю лучше контролировать процесс и снижает вероятность ошибок @userflow_uprock. Визуальное разделение шагов и наличие понятных заголовков обеспечивают лёгкую навигацию. Необходима также мгновенная и ясная обратная связь: при выборе файла отображается его имя и статус загрузки, а при запуске обработки — ход выполнения @nielsen_heuristics. При этом важно предусмотреть возможность возврата к предыдущим шагам без потери данных, что обеспечивает гибкость интерфейса и устойчивость к ошибкам со стороны пользователя.

Визуальное оформление интерфейса должно быть ориентировано на простоту и ясность. Цветовая схема рекомендуется нейтральная, с минимальным количеством акцентов, применяемых только к элементам взаимодействия. Элементы управления должны быть стандартными и визуально предсказуемыми — например, закруглённые блоки с иконками и адекватными отступами способствуют быстрому пониманию их назначения. Чтобы не перегружать новичков, расширенные параметры — такие как количество частей для разбиения или порог слияния — должны быть скрыты по умолчанию и открываться по запросу пользователя. Такой подход позволяет сохранить интерфейс простым для одних и гибким для других @cognitive_load_pixcap.

Интерфейс необходимо адаптировать под различные устройства. Вертикальная компоновка блоков и масштабируемость элементов управления позволяют корректно отображать интерфейс как на настольных компьютерах, так и на мобильных устройствах, что расширяет возможности применения системы в различных условиях @adaptive_design_wiki.

Для наглядного представления логики работы системы были разработаны макеты каждого из четырёх этапов взаимодействия. На рисунке @step-1 показан первый шаг — загрузка файла пользователем. Рисунок @step-2 иллюстрирует отображение загруженных данных и их предварительный просмотр. Рисунок @step-3 демонстрирует настройку параметров обработки, включая доступ к расширенным опциям. На рисунке @step-4 представлен итоговый этап — отображение результатов анализа и отчет, содержащий статистические данные каждого из сегментов. Эти макеты обеспечивают дополнительную ясность при разработке и реализации интерфейса.

#figure(image("assets/1.png"),
    caption: "Макет первого шага" 
) <step-1>

#figure(image("assets/2.png"),
    caption: "Макет второго шага" 
) <step-2>

#figure(image("assets/3.png"),
    caption: "Макет третьего шага" 
) <step-3>

#figure(image("assets/4.png"),
    caption: "Макет четвертого шага" 
) <step-4>

Таким образом, реализация пользовательского интерфейса с опорой на простые и проверенные технологии позволяет достичь высокой функциональности и доступности без лишней сложности. Чёткая структура, минималистичный дизайн, предсказуемое поведение и адаптивность под разные устройства делают интерфейс интуитивно понятным, надёжным и удобным как для начинающих, так и для продвинутых пользователей.

== Проектирование серверной части

Серверный модуль играет центральную роль в функционировании системы, обеспечивая взаимодействие между пользовательским интерфейсом и другими компонентами. Без него пользователь не смог бы отправлять запросы и получать результаты обработки данных. Серверный модуль выступает в качестве связующего звена, принимая запросы от клиентской части и передавая их на обработку в другие модули, а затем возвращая результаты обратно пользователю.

Для обеспечения взаимодействия с другими модулями серверный модуль предоставляет API (программный интерфейс приложения). API определяет набор данных и доступных функций, используя которые другие модули могут обращаться к серверному модулю с конкретными запросами и получать структурированные ответы в определенном формате. Это позволяет различным частям системы взаимодействовать друг с другом независимо от их внутренней реализации.

Для разработки API могут использоваться различные языки программирования и специализированные библиотеки. Язык Python был выбран в качестве основного инструмента благодаря своей простоте, читаемости и поддержке различных парадигм программирования @python. Python также обладает обширной экосистемой библиотек для решения широкого круга задач, включая разработку веб-приложений и API. Среди популярных библиотек для создания API на Python можно выделить FastAPI, Flask и Django.

Для реализации API нашего серверного модуля была выбрана библиотека FastAPI @fastapi. FastAPI представляет собой современный и высокопроизводительный фреймворк для создания API на Python, основанный на стандартах OpenAPI и JSON Schema. Выбор FastAPI обусловлен его скоростью работы, удобством использования, встроенной валидацией данных и автоматической документацией, что делает процесс разработки и поддержки API более эффективным. Одним из ключевых преимуществ FastAPI является его автоматическая генерация документации API в формате Swagger @swagger-link.

Swagger-страница представляет собой интерактивный веб-интерфейс, который содержит подробное описание всех доступных функций API, передаваемых и принимаемых аргументов, доступных версий API и другой полезной информации. Это значительно упрощает процесс интеграции с API как для разработчиков клиентской части, так и для других сервисов, которые могут взаимодействовать с нашей системой. Пример Swagger-страницы приведен на рисунке @swagger.

#figure(
    image("assets/swagger.png"),
    caption: "Пример Swagger-страницы"
) <swagger>

Для запуска разработанного API на основе FastAPI необходимо использовать ASGI-сервер, например Uvicorn.

Uvicorn представляет собой сервер, реализованный на языке Python @uvicorn. ASGI является стандартом для асинхронных веб-серверов и приложений. В отличие от более старого стандарта WSGI (Web Server Gateway Interface), который является синхронным, ASGI позволяет обрабатывать асинхронные запросы и ответы, что особенно важно для современных веб-приложений, требующих высокой производительности и способности обрабатывать большое количество одновременных подключений, таких как API, работающие в режиме реального времени или интенсивно использующие операции ввода-вывода. FastAPI построен на основе асинхронных возможностей Python и использует ASGI для обеспечения своей высокой производительности. Поэтому для запуска приложения FastAPI в production-среде или даже для локальной разработки часто используется именно Uvicorn. Таким образом, Uvicorn выступает в роли "движка", который принимает входящие HTTP-запросы, передает их приложению FastAPI для обработки и затем возвращает ответы клиентам. Использование Uvicorn позволяет FastAPI в полной мере реализовать свои преимущества в плане скорости и эффективности обработки запросов.

Для обеспечения корректного и структурированного обмена данными между клиентским и серверным модулями было принято решение использовать REST API (Representational State Transfer). REST является одним из наиболее популярных архитектурных стилей взаимодействия в распределённых системах благодаря своей простоте, гибкости и совместимости с протоколом HTTP, что делает его особенно удобным для построения клиент-серверных архитектур. Использование REST API позволяет достичь высокой степени разделения ответственности между клиентской и серверной частями системы, обеспечивая при этом масштабируемость и расширяемость архитектуры в будущем.

REST API предоставляет понятные и предсказуемые интерфейсы, построенные на использовании HTTP-методов (таких как GET, POST, PUT, DELETE), что делает его интуитивно понятным для разработчиков и легко тестируемым @restful-api. В контексте данной системы REST API выступает основным механизмом взаимодействия между пользовательским интерфейсом и логикой серверной обработки, позволяя передавать данные, инициировать вычисления и получать результаты. Иллюстрации принципа взаимодействия между клиентом и сервером в процессе обработки пользовательских запросов представленая на рисунке @client-server-interaction-scheme.

#figure(image("assets/client-server.png", width: 50%),
    caption: "Схема взаимодействия клиент-сервер" 
) <client-server-interaction-scheme>

На рисунке показан типовой цикл взаимодействия: от загрузки данных пользователем до получения результатов анализа. Такой подход позволяет ясно структурировать весь процесс обработки, определить границы ответственности между компонентами и облегчить интеграцию новых функциональных возможностей в будущем.

В рамках проектирования API были определены ключевые эндпоинты, каждый из которых выполняет строго ограниченную задачу. Это упрощает сопровождение системы и повышает её надёжность, поскольку изменение или отказ одного эндпоинта не влияет на работу остальных. Кроме того, наличие четко задокументированных интерфейсов позволяет сторонним разработчикам или другим модулям системы легко подключаться к серверному модулю, что особенно важно в условиях возможной масштабной интеграции.

Ключевые API-эндпоинты, предусмотренные на этапе проектирования:

- `POST /upload_file`: эндпоинт для приема файлов данных трафика (CSV, PDF) от клиентского модуля. В теле запроса передается файл. Разделение загрузки данных от анализа позволяет повысить гибкость и масштабируемость архитектуры.

- `POST /start_analysis`: эндпоинт для запуска процесса анализа данных. В теле запроса передаются параметры анализа, заданные пользователем через графический интерфейс (например, желаемое количество сегментов для генетического алгоритма, параметры алгоритма и т. д.). Серверный модуль передает эти параметры модулю анализирования.

- `GET /get_status`: эндпоинт для запроса текущего статуса выполнения анализа (например, "в ожидании", "загружен", "обработка данных", "анализ завершен", "ошибка"). Ответ возвращается в формате JSON и позволяет клиенту отслеживать прогресс и состояние запроса без постоянного взаимодействия с сервером.

- `GET /get_results`: эндпоинт для получения результатов завершенного анализа. Ответ содержит сегментированные данные, статистические характеристики сегментов и данные для визуализации (графики), представленные в формате JSON. Это обеспечивает удобство последующей обработки и отображения результатов на клиентской стороне.

Таким образом, проектирование серверного модуля и REST API позволило создать чёткую архитектурную основу для взаимодействия компонентов системы, обеспечивая прозрачность, расширяемость и высокую степень автоматизации при дальнейшей разработке и эксплуатации.

=== Проектирование модуля обработки входных данных

Модуль обработки входных данных, обеспечивает начальный этап работы интеллектуальной системы прогнозирования и планирования интенсивности движения. Его задача -- привести входные данные, полученные от пользователя в формате PDF или CSV, к структурированному и унифицированному виду, пригодному для последующего анализа. Модуль включает два логически связанных компонента: компонент извлечения данных (парсинг) и компонент преобразования (агрегация и фильтрация). Модуль должен поддерживать загрузку исходных данных в двух форматах: PDF и CSV.

PDF -- используется в случае, если данные поступают в виде отсканированных или экспортированных из других систем отчётов, содержащих таблицы с временными рядами. Пример формата таких таблиц представлен на рисунке @pdf-table.;
#figure(image("assets/pdf.png"),
    caption: "Пример таблицы в формате PDF" 
) <pdf-table>

Номер сектора - номер определенной области, где находится данный перекресток. Номер ДК - номер дорожного котроллера для данного перекрестка. Номер направления - индекс направления, по которому проводились измерения. Начало интервала накопления - время, начинаю с которого детектор вел подсчет количества автомобилей. Интервал накопления - время, в течение которого детектор фиксирует количество автомобилей.Номер характеристики - индекс характеристики движения по данному направлению, которая измеряется (в нашем случае интенсивность движения). Интенсивность - количество автомобилей, зафиксированных в течение интервала накопления. 

CSV -- предпочтительный формат, если данные уже представлены в табличном виде, подготовленном для автоматической обработки. В этом случае этап парсинга опускается, и данные сразу направляются в компонент преобразования. Пример структуры такой таблицы показан на рисунке @csv-table.


#figure(image("assets/csv.png"),
    caption: "Пример таблицы в формате CSV" 
) <csv-table>

Для парсинга PDF-документов была выбрана библиотека Camelot, которая зарекомендовала себя как инструмент, специально ориентированный на точное и гибкое извлечение табличных данных из PDF @camelot. 

Ключевыми преимуществами Camelot стали её специализация на работе с табличной структурой, что обеспечивает точное позиционирование ячеек даже при слабой разметке и отсутствии явных границ таблиц; высокая гибкость и возможность детальной настройки параметров извлечения, что позволяет эффективно обрабатывать документы с разнообразной структурой; а также простая интеграция с Python — библиотека написана на этом языке и не требует дополнительных зависимостей, таких как Java, что делает её оптимальным решением в рамках проекта, где весь серверный стек реализован на Python. В качестве альтернативных решений рассматривалась библиотека Tabula-py — Python-обёртка над Java-библиотекой Tabula, которая обеспечивает высокую точность при извлечении простых таблиц, но требует установленной Java и обладает ограниченными возможностями настройки @tabula. Библиотека PyPDF2 предоставляет базовые средства для извлечения текста из PDF, однако не имеет встроенных механизмов работы с табличными структурами @pymupdf. PyMuPDF показывает высокую производительность при рендеринге и извлечении различного контента из PDF-документов, но не поддерживает прямое распознавание таблиц @pymupdf.

После извлечения таблиц (или прямого получения CSV-файла) данные поступают во второй компонент — преобразования и агрегации. На этом этапе выполняется унификация временных рядов, фильтрация по дням недели и интерполяция пропущенных значений.

Для реализации данного этапа используется библиотека pandas, являющаяся стандартом де-факто в области анализа данных на Python благодаря своей высокой производительности при работе с табличными структурами. Её тесная интеграция с NumPy обеспечивает удобную обработку числовых массивов, а гибкие возможности трансформации данных — такие как группировка, агрегация, интерполяция и работа с временными индексами — делают её особенно подходящей для задач предобработки временных рядов. Дополнительными преимуществами являются широкое сообщество пользователей и обширная документация, что способствует ускоренной разработке и упрощает поддержку кода.

После извлечения или загрузки данных начинается этап преобразования: таблица приводится к формату с индексами по дате и направлению движения, временные метки округляются до ближайшего интервала накопления. Далее выполняется фильтрация по дням недели, интерполяция пропусков и агрегация в структуру день × направление × интервал, пригодную для анализа.

Таким образом модуль должен обеспечить автоматическую обработку входных данных в форматах PDF и CSV, приводя их к единому структурированному виду. Это упростит последующий анализ и повысит надёжность решения, независимо от в каком формате -- PDF или CSV -- данных.

=== Проектирование модуля анализирования

Модуль анализирования, схема которого представлена на рисунке @analizis_module_scheme, представляет собой центральный компонент системы, отвечающий за выполнение анализа временных рядов. Его основная задача — выявление закономерностей в данных, полученных на предыдущем этапе обработки, и формирование сегментов, которые будут использоваться для дальнейшего прогнозирования и планирования интенсивности движения.

#figure(image("схемы/схема_модуля_анализирования_для_отчета.png", height: 67%),
    caption: "Блок-схема генетического алгоритма" 
) <analizis_module_scheme>

В первой главе был проведён обзор существующих подходов к сегментации временных рядов. Анализ показал, что большинство методов обладают рядом ограничений, которые делают их слабо применимыми для обработки реальных транспортных данных. 

Методы кластеризации, несмотря на разнообразие подходов и теоретическую способность выявлять структуры с высокой межкластерной разницей и низкой внутрикластерной дисперсией, на практике сталкиваются с рядом серьёзных ограничений. Во-первых, они не обеспечивают прямого механизма ограничения размера кластеров, особенно по временной оси, что критично для транспортных задач. Во-вторых, многие алгоритмы демонстрируют недостаточную устойчивость к шуму, характерному для реальных данных интенсивности движения, что приводит к снижению точности сегментации и появлению артефактов в виде ложных границ сегментов. В-третьих, качество разграничения сегментов часто оказывается неудовлетворительным — алгоритмы могут создавать сегменты с высокой внутренней вариацией или, наоборот, объединять принципиально разные временные интервалы, не обеспечивая максимального различия между соседними сегментами. В задачах планирования интенсивности движения, где необходимо контролировать длительность сегментов или обеспечить равномерное распределение объектов между кластерами, такие алгоритмы оказываются либо неприменимыми, либо требуют сложных обходных решений. Более того, многие методы кластеризации не позволяют явно задать желаемое число кластеров, что критично в прикладных сценариях с фиксированными требованиями к выходной структуре.

Методы обнаружения точек изменений сталкиваются с аналогичными ограничениями в области точности и качества сегментации. Они не обеспечивают прямого управления длиной и числом сегментов, что критически важно в прикладных задачах планирования, где требуется предсказуемая и управляемая структура выходных данных. В отличие от кластеризации, эти методы часто не гарантируют оптимального разграничения сегментов: результирующие сегменты могут иметь высокую внутреннюю вариацию при низком различии между соседними интервалами, что противоречит основным принципам качественной сегментации. Особенно остро эта проблема проявляется в условиях шума и плавных переходов между режимами движения, когда алгоритмы либо пропускают реальные точки изменений, либо создают ложные границы. Сегменты могут значительно отличаться по длине и статистическим характеристикам, не имея чёткой интерпретации. Кроме того, многие алгоритмы данной группы требуют жёсткой структуры входных данных или предварительного задания количества сегментов, оказываются неустойчивыми к шуму, плохо масштабируются и сильно зависят от настройки гиперпараметров.

Наиболее близким к практическим требованиям является метод динамического программирования, поскольку он позволяет задать фиксированное количество сегментов и обеспечивает глобально оптимальное разбиение по функции стоимости. Однако он также не решает задачу в полном объёме, поскольку не позволяет одновременно учитывать все необходимые требования: максимизацию различий между сегментами, минимизацию внутрисегментной дисперсии, а также наличие жёстких ограничений как на количество, так и на длину сегментов.

Таким образом, существующие методы не обеспечивают комплексного решения задач сегментации временных рядов интенсивности движения, которые характеризуются высокой неоднородностью, отсутствием явной структуры и варьирующей длиной естественных сегментов, при одновременной необходимости соблюдения строгих ограничений на структуру выходных данных.

Учитывая выявленные ограничения существующих подходов, в настоящей работе предлагается метод на основе генетического алгоритма, который позволяет одновременно решить основные проблемы: обеспечить контроль над количеством и длиной сегментов, максимизировать различия между сегментами при минимизации внутрисегментной дисперсии, а также сохранить устойчивость к шуму.

Для оценки качества работы алгоритмов и их соответствия требованиям были предложены 4 метрики: внутрисегментная вариация ($V$), межсегментная разность ($D$), доля сегментов, не удовлетворяющих минимальной длине ($S S R$), отклонение числа сегментов ($S E$); а также дополнительно время работы алгоритма ($t$).

Внутрисегментная вариация представляет собой усреднённую величину, характеризующую степень разброса элементов внутри каждого сегмента относительно его центра. Данная метрика отражает внутреннюю однородность сегментов: чем меньше её значение, тем более однородны данные внутри сегментов.

Вычисление центроида сегмента производится по формуле @mu:
$
  mu_s = 1/abs(I_s) sum_(i in I_s)x_i
  text(",", font: "Times New Roman")
$ <mu>

#indetless[где $mu_s$ — центроид сегмента $s$;]

$I_s$ — множество индексов элементов, принадлежащих сегменту $s$;

$x_i in RR^d$ — вектор размерности $d$ для элемента $i$.

Внутрисегментная вариация вычисляется по формуле @V:
$
 V = 1/S sum_(s=1)^S 1/abs(I_s) sum_(i in I_s) abs(abs(x_i - mu_s))
 text(",", font: "Times New Roman")
$ <V>

#indetless[где $V$ — внутрисегментная вариация;]

$S$ — общее число сегментов;

$I_s$ — множество индексов элементов в сегменте $s$;

$x_i in RR^d$ — вектор размерности $d$ для элемента $i$;

$mu_s$ — центроид сегмента $s$, вычисленный по формуле @mu.

Межсегментная разность является усреднённой мерой различий между соседними сегментами и характеризует степень контрастности между ними. Эта метрика отражает различие между сегментами: чем больше её значение, тем сильнее отличаются соседние сегменты друг от друга.

Межсегментная разность вычисляется по формуле @D:

$
  D = 1/(S-1) sum_(s=1)^(S-1) abs(abs(mu_s - mu_(s+1)))
  text(",", font: "Times New Roman")
$ <D>

#indetless[где $D$ — межсегментная разность;]

$S$ — общее число сегментов;

$mu_s$ и $mu_(s+1)$ — центроиды соседних сегментов $s$ и $s+1$, вычисленные по формуле @mu.

Доля сегментов, не удовлетворяющих минимальной допустимой длине, представляет собой отношение количества сегментов, длина которых меньше $L_min$, к общему числу сегментов:

$
  S S R = abs({s: abs(I_s)<L_min})/S
  text(",", font: "Times New Roman")
$ <SSR>

#indetless[где $S S R$ — доля сегментов, не удовлетворяющих минимальной длине;]

$S$ — общее число сегментов;

$L_min$ — минимальная допустимая длина сегмента.

Отклонение числа сегментов вычисляется по формуле @SE:
$
  S E = abs(S - S^*) / S
  text(",", font: "Times New Roman")
$ <SE>

#indetless[где $S E$ — отклонение числа сегментов;]

$S$ — фактическое общее число сегментов;

$S^*$ — требуемое общее число сегментов.

Без нормализации значений внутрисегментная вариация и межсегментная разность напрямую зависят от масштаба признаков, что затрудняет объективное сравнение. Поэтому используются нормализованные версии метрик, обеспечивающие сопоставимость качества сегментации между различными наборами данных и параметрами.

Нормализованная внтурисегментная вариация вычисляется по формуле @V_norm: 
$ 
  V_norm = V/(max_(i,j)abs(abs(x_i - x_j)))
  text(",", font: "Times New Roman")
$ <V_norm>

#indetless[где $V_norm$ -- нормализованная внутрисегментная вариация;]

$V$ -- внутрисегментная вариация, вычисленная по формуле @V;

$x_i$, $x_j$ $in RR^d$ -- вектора размерности $d$ для элементов $i$, $j$.

Нормализованная внтурисегментная вариация вычисляется по формуле @D_norm: 
$ 
  D_norm = D/(max_(i,j)abs(abs(x_i - x_j)))
  text(",", font: "Times New Roman")
$ <D_norm>

#indetless[где $D_norm$ -- нормализованная внутрисегментная вариация;]

$D$ -- внутрисегментная вариация, вычисленная по формуле @D;

$x_i$, $x_j$ $in RR^d$ -- вектора размерности $d$ для элементов $i$, $j$.

Итак, в таблице @compare представлены результаты сравнения различных алгоритмов кластеризации по предложенным метрикам качества: нормализованной внутрисегментной вариации ($V_norm$), нормализованной межсегментной разности ($D_norm$​), доле сегментов, не удовлетворяющих минимальной длине ($S S R$), отклонению числа сегментов ($S E$) и времени работы алгоритма ($t$).

Итак, в таблице @compare представлены результаты сравнения различных алгоритмов кластеризации по предложенным метрикам: $V_norm$, $D_norm$, $S S R$, $S E$ и времени работы $t$.

#import table: cell

#figure(
  table(
    align: (x, y) =>
      if y == 0 { center }
      else if x == 0 { left }
      else { center },
    columns: (4fr, 1fr, 1fr, 1fr, 1fr, 1fr),
    [], [*$V_norm$*], [*$D_norm$*], [*$S S R$*], [*$S E$*], [*$t$, с*],
    cell(colspan: 6, align: center, [Методы кластеризации]),
    [Экспертные правила],         [0.06], [0.29], [0.21], [0.39], [15.2],
    [Пороговая],                  [0.08], [0.41], [0.23], [0.10], [0.1],
    [k-means],                    [0.12], [0.49], [0.26], [0.29], [0.2],
    [DBSCAN],                     [0.14], [0.36], [0.02], [0.79], [1.0],
    [Гауссовой смесь],            [0.09], [0.46], [0.24], [0.26], [2.0],
    [Пуассоновской смесь],        [0.11], [0.47], [0.20], [0.21], [2.1],
    [Агломеративная],             [0.07], [0.51], [0.12], [0.09], [1.0],
    [Finch],                      [0.09], [0.39], [0.08], [0.16], [7.6],
    [TW-Finch],                   [0.08], [0.42], [0.06], [0.12], [11.2],
    // [*Агломеративная рекурсивная*], [*0.06*], [*0.44*], [*0.00*], [*0.00*], [*2.9*],
    cell(colspan: 6, align: center, [Методы поиска точек изменения]),
    [Clasp],                      [0.19], [0.26], [0.05], [0.61], [20.3],
    [Pointer Networks],           [0.18], [0.31], [0.09], [0.59], [250.8],
    [Kernel Change Detection],    [0.19], [0.14], [0.31], [0.39], [7.5],
    [Binary],                     [0.16], [0.30], [0.19], [0.31], [6.3],
    [Bottom-Up],                  [0.14], [0.32], [0.18], [0.26], [6.1],
    [Window Sliding],             [0.13], [0.33], [0.20], [0.31], [6.1],
    [Pelt],                       [0.12], [0.41], [0.09], [0.21], [7.0],
    [Dynamic Programming],        [0.04], [0.54], [0.00], [0.00], [210.1],
    [*Генетический алгоритм*],      [*0.04*], [*0.60*], [*0.00*], [*0.00*], [*180.6*],
  ),
  caption: "Сравнение алгоритмов разделения на сегменты"
) <compare>

Как видно из таблицы @compare, лучшее сочетание качества сегментации демонстрирует предлагаемый генетический алгоритм (GA), который превосходит существующие методы по ключевым показателям.

Генетический алгоритм, схема которого представлена на рисунке @genetic-algorithm, кодирует разбиение временного ряда в виде хромосом — например, бинарных масок точек разрыва — и оценивает их по формуле @F и оптимизирует с помощью операторов мутации, скрещивания и селекции. В отличие от жёстких методов (например, Binary Segmentation), GA не требует знания точного количества сегментов и способен эффективно работать в условиях шума, выбросов, разной плотности кластеров и высокой размерности данных. Его стохастическая природа позволяет избегать локальных минимумов, а гибкость в выборе функции стоимости — адаптировать подход под любые метрики качества.

#figure(image("схемы/схема_генетического_алгоритма.png", height: 97%),
    caption: "Блок-схема генетического алгоритма" 
) <genetic-algorithm>

Математически функция оценки пригодности (F) выражается формулой @F:
$
    F = w_1 ⋅ D_(n o r m) - w_2 ⋅ P_(s i z e) - w_3 ⋅ P_(r a n g e)
    text(",", font: "Times New Roman")
$ <F>

#indetless[где $D_(n o r m)$ — нормализованная сумма евклидовых расстояний между средними векторами сегментов;]
- $P_(s i z e)$ — штраф за неравномерность размеров сегментов;
- $P_(r a n g e)$ — штраф за неоднородность диапазонов значений в сегментах;
- $w_1$, $w_2$, $w_3$ — весовые коэффициенты важности критериев.

Для реализации предлагаемого генетического алгоритма была выбрана библиотека DEAP, предоставляющая удобные механизмы для построения эволюционных алгоритмов. Одним из ключевых факторов выбора стало наличие встроенных инструментов для настройки операторов мутации, скрещивания и отбора, а также поддержка параллельных вычислений, что критично при работе с большими объёмами данных @deap. Гибкость DEAP позволила адаптировать алгоритм под конкретные требования, включая контроль количества кластеров, их размера и однородности. Благодаря этим преимуществам DEAP стал оптимальным выбором для реализации предложенного метода.

=== Проектирование модуля формирования отчётных данных

Модуль формирования отчётных данных должен обеспечивать как графическое, так и табличное представление результатов кластерного анализа временных рядов. Его основная задача — предоставить пользователю интерпретируемую и наглядную информацию о кластерной структуре данных, полученной на предыдущих этапах обработки.

Проектом предусмотрено использование визуализации временных рядов с выделением кластеров с помощью цветовой кодировки. Такая визуализация должна быть организована по направлениям движения: для каждого направления на графике должны отображаться исходные значения, участки кластеров, а также аннотации со сводной статистикой (средними значениями и диапазонами изменений). Использование различных цветов и адаптивное позиционирование подписей позволит избежать наложений и сохранить читаемость графиков. Это способствует быстрому визуальному анализу структуры кластеров и выявлению типовых шаблонов поведения.

Для дополнения графического отчёта должна быть предусмотрена табличная форма представления данных. Таблица должна содержать для каждого кластера средние значения, диапазоны интенсивности по направлениям и соответствующие временные интервалы. Принципиально важно, чтобы структура таблицы позволяла использовать её как в автономных отчётах (например, PDF или Excel), так и в рамках веб-интерфейса.

Также необходимо, чтобы визуальная часть отчёта преобразовывалась в формат, пригодный для встраивания или хранения без зависимости от файловой системы (например, base64) @base64_encoding. Это решение позволит легко передавать отчётные данные через API, сохранять их в базе данных и использовать в других компонентах системы.

Таким образом, модуль отчётности спроектирован как универсальный инструмент визуального и табличного представления результатов анализа. Он должен обеспечивать как техническую точность, так и удобство восприятия для пользователей, не обладающих технической подготовкой.

= Реализация и испытание системы 

== Реализация и тестирование модуля графического интерфейса

Веб-интерфейс реализован в соответствии с проектными решениями с использованием чистых HTML, CSS и JavaScript, без применения сторонних фреймворков. Архитектура приложения базируется на трех основных файлах: `index.html`, в котором размещена структура интерфейса с четырьмя последовательными шагами, `styles.css`, отвечающем за визуальное оформление и адаптивность, и `script.js`, реализующем логику взаимодействия и управления состояниями.

Переходы между шагами управляются динамически за счёт изменения CSS-классов, отражающих текущее состояние каждого этапа: активный, завершённый или неактивный. В интерфейсе предусмотрена возможность возврата к предыдущим этапам с полным восстановлением исходных значений, что позволяет пользователю свободно перемещаться между шагами без потери введённых данных или сбоя в логике работы приложения.

Для отображения прогресса длительных операций реализован механизм опроса состояния, который с заданной периодичностью получает от сервера актуальную информацию. Это обеспечивает обратную связь в реальном времени без блокировки интерфейса, а при завершении процесса или возникновении ошибок опрос автоматически прекращается.

Обмен данными с серверной частью осуществляется через REST API с использованием Fetch API. Каждая операция получает уникальный идентификатор, позволяющий отслеживать её статус на протяжении всего выполнения. Загрузка файлов производится с помощью FormData и включает клиентскую валидацию, что обеспечивает поддержку корректных форматов (например, CSV и PDF) и предотвращает передачу неподдерживаемых типов.

Адаптивность интерфейса обеспечивается с помощью Flexbox и использования относительных единиц измерения, что делает интерфейс удобным для работы как на мобильных устройствах, так и на больших экранах. Дополнительные параметры анализа, скрытые по умолчанию, можно развернуть по желанию пользователя. Это делает интерфейс простым и понятным при первичном использовании, не лишая при этом гибкости для опытных пользователей. Для предотвращения ошибок ввода в числовые поля применяются защитные механизмы, блокирующие некорректные действия.

Интерфейс организован в виде пошаговой последовательности с интуитивно понятными элементами управления и визуальной обратной связью, как показано на рисунке @interfase.

#figure(image("assets/interface.png"),
    caption: "Веб-интерфейс" 
) <interfase>

Тестирование проводилось всесторонне: проверялась работа всех шагов пользовательского сценария, валидация файлов, корректность отображения и сохранения параметров, а также получение результатов анализа с отображением визуальных данных. Интерфейс был проверен на адаптивность и стабильность работы на разных экранах, а также на корректность отображения элементов при переходах между этапами.

Особое внимание уделялось механизму восстановления состояния при возврате на предыдущие шаги, а также обработке ошибок — например, при загрузке неподдерживаемых файлов, сбоях соединения или проблемах на сервере. В рамках кроссбраузерного тестирования была подтверждена корректная работа интерфейса во всех основных браузерах.

В процессе тестирования были выявлены и устранены несколько незначительных проблем, связанных с состоянием интерфейса при быстрой навигации между этапами. Финальная версия системы демонстрирует устойчивую и предсказуемую работу, обеспечивая удобный и понятный пользовательский опыт, полностью соответствующий требованиям проекта по анализу временных данных.

== Реализация и тестирование серверного части

Серверный модуль реализован на Python с использованием фреймворка FastAPI в соответствии с архитектурными решениями, изложенными ранее. В главном файле приложения определены все необходимые маршруты и реализована логика обработки пользовательских запросов.

Для управления загрузкой и обработкой файлов применяется система отслеживания процессов на основе уникальных идентификаторов. Каждый процесс проходит через пять последовательных этапов: выбор типа файла, загрузка, предварительная обработка, настройка параметров и анализ. Состояния процессов сохраняются в оперативной памяти сервера, что обеспечивает быстрый доступ к текущей информации и позволяет в реальном времени отображать прогресс на клиентской стороне.

Обработка входящих файлов сопровождается проверкой форматов и сохранением на сервере. Для повышения отзывчивости системы используется асинхронная обработка — анализ и преобразование данных выполняются в фоновом режиме, позволяя серверу сразу отправлять подтверждение получения и не блокировать интерфейс пользователя.

Поддерживается работа с CSV и PDF. Для PDF-документов реализована автоматическая обработка табличных данных с помощью библиотеки Camelot, обеспечивающей извлечение таблиц и их конвертацию в удобный для анализа формат. Дополнительно выполняется очистка и структурирование информации, включая корректное разбиение столбцов и приведение полей к требуемой структуре.

Для проверки корректности входных данных используются модели, описанные с помощью Pydantic. Они обеспечивают строгую типизацию и валидацию параметров анализа, а также формируют понятные сообщения об ошибках. Настройки анализа, такие как выбор дней недели, количество сегментов и пороговые значения, передаются серверу и сохраняются для дальнейшего использования в процессе вычислений.

Анализ данных запускается асинхронно: параметры преобразуются во внутренний формат, совместимый с аналитическим модулем, и передаются в алгоритм, выполняющий основной расчет. Результаты возвращаются в виде JSON, включая изображения графиков и таблицы в HTML-формате.

Механизмы обработки ошибок реализованы комплексно: все ключевые операции защищены от сбоев с помощью конструкции обработки исключений. В случае ошибок статус процесса обновляется соответствующим образом, что позволяет клиенту корректно отобразить ситуацию и, при необходимости, повторить операцию.

Тестирование серверного модуля проводилось поэтапно. Каждый маршрут API проверялся как на корректную работу с допустимыми данными, так и на устойчивость при ошибках, включая нарушения порядка вызова, передачу некорректных файлов и параметров. Тестирование охватывало также взаимодействие всех компонентов системы: загрузка, промежуточная обработка, анализ и возврат результатов.

Особое внимание было уделено проверке фоновых задач и корректности обновления статуса процессов во время выполнения. Сценарии с параллельной обработкой запросов позволили оценить производительность и выявить узкие места при работе под нагрузкой. Также была протестирована совместимость с реальными данными различного объема и структуры, включая PDF-файлы с нетипичными таблицами.

Встроенная Swagger-документация прошла верификацию на соответствие фактическому поведению API, что обеспечило удобную и точную платформу для тестирования запросов. Результаты тестирования подтвердили стабильность, производительность и готовность серверного модуля к эксплуатации в составе полной системы анализа временных данных.

=== Реализация и тестирование модуля обработки входных данных

Модуль обработки входных данных реализован на языке Python с использованием специализированных библиотек для работы с табличными и полуструктурированными данными. Обработка PDF-документов осуществляется с помощью библиотеки Camelot, которая позволяет извлекать таблицы с каждой страницы документа. Используется алгоритм распознавания структуры `lattice`, обеспечивающий точное определение границ таблиц при наличии четкой разметки. Извлеченные таблицы объединяются в единый DataFrame, очищаются от артефактов и приводятся к унифицированной структуре с ожидаемыми именами столбцов. Результат сохраняется в CSV-формате, что позволяет применять универсальную логику дальнейшей обработки независимо от исходного типа файла.

Обработка CSV-файлов реализована в функции `process_csv()`, которая выполняет весь цикл преобразования данных об интенсивности движения. Входными параметрами являются путь к файлу и список дней недели, по которым необходимо отфильтровать данные. Основной задачей является агрегация интенсивностей в заданных временных интервалах, фильтрация по дате и направление движения, а также интерполяция пропущенных значений. В результате функция возвращает структурированный словарь, содержащий идентификатор контроллера, список уникальных дат, направления движения, временные интервалы и трехмерный массив интенсивностей.

```
def process_csv(file_path, days):
    df = pd.read_csv(file_path)
    id = int(df['dkNum'].iloc[0])
    df['date'] = pd.to_datetime(df['date'], format="%d-%m-%y")
    accumulationInterval = df['accumulationInterval'].iloc[0]
    df = df.pivot(index=['date', 'directionNum'],
                  columns='accumulationStartTime', values='intensity')

    def floor_to(time_str):
        dt = pd.to_datetime(time_str, format='%H:%M:%S')
        minute = dt.minute - (dt.minute % accumulationInterval)
        floored = dt.replace(minute=minute, second=0)
        return floored.strftime('%H:%M:%S')

    timestamps = [col for col in df.columns if col not in [
        'accumulationStartTime', 'date', 'directionNum']]
    rename_mapping = {col: floor_to(col) for col in timestamps}
    time_df = df[timestamps].rename(columns=rename_mapping)

    aggregated_time = pd.DataFrame(index=time_df.index)
    for new_col in time_df.columns.unique():
        subset = time_df.loc[:, time_df.columns == new_col]
        aggregated_time[new_col] = subset.sum(axis=1, min_count=1)
    df = aggregated_time
    timestamps = [col for col in df.columns if col not in [
        'accumulationStartTime', 'date', 'directionNum']]

    weekdays_df = df[df.index.get_level_values('date').dayofweek.isin(days)]
    weekdays_df = weekdays_df.interpolate(
        method='linear', axis=1, limit_direction='both')

    indices = list(weekdays_df.index)
    dates, directions = zip(*indices)
    dates = np.unique(np.array([d.strftime('%Y-%m-%d') for d in dates]))
    directions = np.unique(np.array(directions))
    n_directions = directions.shape[0]

    weekdays_df = weekdays_df.to_numpy()
    n_rows, n_cols = weekdays_df.shape
    intensities = weekdays_df.reshape(
        n_rows // n_directions, n_directions, n_cols)

    return {
        "id": id,
        "dates": dates,
        "timestamps": timestamps,
        "directions": directions,
        "intensities": intensities
    }
```

Интерполяция пропущенных значений реализована встроенным методом с линейным подходом и направлением заполнения в обе стороны. Это позволяет восстанавливать значения даже при наличии разрывов на границах временных интервалов, не нарушая при этом общий тренд в данных. Финальное преобразование обеспечивает получение массива фиксированной размерности: по числу дней, направлений и временных меток.

Тестирование модуля проводилось на наборах реальных данных с различной структурой и степенью полноты. Были проверены сценарии с корректными CSV-файлами, файлами с пропущенными значениями и файлами, содержащими нестандартные временные интервалы. Валидация обработки PDF-документов проводилась на примерах с различным качеством сканирования и структурой таблиц: от четко размеченных до слабоструктурированных. Библиотека Camelot показала высокую устойчивость к разнообразию входных документов, при необходимости обеспечивая настройку параметров извлечения.

Проверка результатов обработки включала контроль за сохранением исходного количества наблюдений, корректностью формирования временных осей и соответствием размерностей получаемого массива ожидаемым. Интерполяция проверялась на искусственно созданных пропусках разной протяженности, показав эффективность заполнения при интервалах до 2–3 временных отсчетов. Отдельная проверка фильтрации по дням недели подтвердила правильность исключения выходных при соответствующих настройках.

Производительность модуля оценивалась на крупных входных файлах объёмом до 50 МБ с данными за продолжительные периоды. Тестирование показало устойчивую и предсказуемую работу при последовательной и параллельной обработке, что подтверждает готовность компонента к использованию в составе полной аналитической системы.

=== Реализация и тестирование модуля анализирования

Центральным компонентом модуля является функция `partition_array_ga`, реализующая генетический алгоритм для оптимального разбиения временных рядов на сегменты. Алгоритм основан на библиотеке DEAP и использует специализированную функцию оценки пригодности особей. Каждая особь в популяции представляет собой список границ разбиения, где каждый элемент определяет позицию разделения временного ряда. Функция `create_individual` генерирует случайные, но валидные границы сегментов с учетом ограничения на минимальную ширину:

```
def create_individual():
    # Распределить дополнительные столбцы случайным образом
    extra = N - num_parts * min_width
    dividers = sorted(random.sample(range(1, extra + 1), num_parts - 1))
    
    # Преобразовать в фактические граничные положения
    boundaries = []
    cum_sum = 0
    for i in range(num_parts - 1):
        if i == 0:
            cum_sum += min_width + dividers[0]
        else:
            cum_sum += min_width + (dividers[i] - dividers[i-1])
        boundaries.append(cum_sum)
    
    return boundaries
```

Качество разбиения оценивается многокритериальной функцией `evaluate`, учитывающей три ключевых фактора: максимизацию различий между сегментами, равномерность их размеров и однородность диапазонов значений внутри сегментов по формуле @F:

```
def evaluate(individual):
    partitions = get_partitions(individual, N)
    
    # Вычисление векторов средних значений для каждой части
    mean_vectors = []
    range_vectors = []
    partition_sizes = []
    
    for start, end in partitions:
        block = array[:, start:end]
        mean_vector = np.mean(block, axis=1)
        range_vector = np.max(block, axis=1) - np.min(block, axis=1)
        
        mean_vectors.append(mean_vector)
        range_vectors.append(range_vector)
        partition_sizes.append(end - start)
    
    # Максимизация различий между частями
    total_diff = 0
    for i in range(len(mean_vectors)):
        for j in range(i+1, len(mean_vectors)):
            total_diff += np.linalg.norm(mean_vectors[i] - mean_vectors[j])
    
    # Штраф за неравномерность размеров
    ideal_size = N / num_parts
    size_penalty = (np.std(partition_sizes) / ideal_size) * size_penalty_weight
    
    # Штраф за неоднородность диапазонов
    mean_ranges = [np.mean(range_vec) for range_vec in range_vectors]
    range_cv = np.std(mean_ranges) / (np.mean(mean_ranges) + 1e-10)
    range_penalty = range_cv * range_uniformity_weight
    
    # Итоговая оценка пригодности
    fitness = diff_weight * (total_diff / (num_parts * (num_parts - 1) / 2)) - size_penalty - range_penalty
    
    return (fitness,)
```

Для эволюции популяции используются стандартные генетические операторы. Оператор скрещивания `tools.cxOnePoint` выполняет одноточечный кроссовер, объединяя границы разбиения от двух родительских особей. Оператор мутации `mutate_boundaries` случайным образом изменяет позиции границ с учетом ограничений минимальной ширины сегментов:

```
def mutate_boundaries(individual, indpb=0.3):
    for i in range(len(individual)):
        if random.random() < indpb:
            # Вычисление допустимого диапазона для границы
            if i == 0:
                min_val = min_width
            else:
                min_val = individual[i-1] + min_width

            if i == len(individual) - 1:
                max_val = N - min_width
            else:
                max_val = individual[i+1] - min_width

            if min_val < max_val:
                individual[i] = random.randint(min_val, max_val)

    return (individual,)
```

Селекция осуществляется турнирным отбором `tools.selTournament` с размером турнира 3, что обеспечивает баланс между давлением отбора и разнообразием популяции.

После получения оптимального разбиения применяется иерархическая кластеризация для объединения схожих сегментов. Функция `cluster_parts_by_threshold` использует пороговый алгоритм, основанный на процентилях матрицы различий между сегментами:

```
def cluster_parts_by_threshold(diff_matrix, threshold_percentile=25):
    # Вычисление порога на основе процентиля
    upper_triangle = diff_matrix[np.triu_indices_from(diff_matrix, k=1)]
    threshold = np.percentile(upper_triangle, threshold_percentile)
    
    # Инициализация кластеров
    num_parts = diff_matrix.shape[0]
    cluster_labels = np.arange(num_parts)
    
    # Итеративное объединение близких кластеров
    while True:
        merged = False
        min_diff = float('inf')
        merge_i, merge_j = -1, -1
        
        for i in range(num_parts):
            for j in range(i + 1, num_parts):
                if (cluster_labels[i] != cluster_labels[j] and 
                    diff_matrix[i, j] < threshold and 
                    diff_matrix[i, j] < min_diff):
                    min_diff = diff_matrix[i, j]
                    merge_i, merge_j = i, j
        
        if min_diff < threshold:
            old_label = cluster_labels[merge_j]
            new_label = cluster_labels[merge_i]
            cluster_labels[cluster_labels == old_label] = new_label
            merged = True
        
        if not merged:
            break
    
    return normalized_labels, threshold
```

Для каждого выявленного кластера функция `analyze_clusters` вычисляет статистические характеристики, включая средние значения интенсивности и диапазоны колебаний по временным периодам:

``` 
def analyze_clusters(array, partition_boundaries, cluster_labels):
    cluster_stats = {}
    
    for i in range(num_parts):
        start, end = partition_boundaries[i], partition_boundaries[i+1]
        cluster_id = cluster_labels[i]
        
        for row in range(M):
            data = array[row, start:end]
            if cluster_id not in cluster_stats:
                cluster_stats[cluster_id] = {
                    'mean_values': np.mean(data),
                    'range_values': np.max(data) - np.min(data)
                }
    
    return cluster_stats
```

Обработка данных также содержит извлечение минимальных и максимальных значений по каждому сегменту, которые затем используются для построения матрицы евклидовых расстояний между векторами признаков. Это позволяет выявить степень схожести между сегментами и служит основой для кластеризации. На заключительном этапе смежные сегменты, отнесённые к одному кластеру, объединяются в непрерывные временные интервалы, что позволяет представить результаты в виде целостных и интерпретируемых фрагментов поведения.

Тестирование генетического алгоритма проводилось на синтетических данных с известной структурой сегментации для проверки корректности кодирования особей, монотонности функции оценки и сходимости алгоритма. Все сгенерированные границы соответствовали ограничениям минимальной ширины сегментов, а решения с более выраженными различиями между сегментами получали более высокие оценки пригодности.

Полный процесс анализа проходил тестирование на реальных данных интенсивности транспортного потока с акцентом на оценку устойчивости кластеризации, адекватности разметки и вычислительной эффективности. При сравнении с экспертной сегментацией метод показал более стабильные и последовательные результаты, особенно на граничных участках. Среднее время обработки одного временного ряда составляет около одной минуты, а показатель стабильности между запусками достигает 0.99, что свидетельствует о высокой воспроизводимости получаемых интервалов.

=== Реализация и тестирование модуля формирования отчётных данных

Модуль формирования отчётных данных обеспечивает графическое и табличное представление результатов анализа временных рядов. Визуализация реализована в виде многоуровневых графиков, на которых участки, принадлежащие разным кластерам, выделяются различными цветами. Это позволяет наглядно отразить структуру и динамику сегментированных данных по каждому направлению движения. Для обеспечения визуального различия используется расширенная цветовая палитра, подходящая даже при большом количестве кластеров.

Особое внимание уделено способу отображения статистики кластеров на графиках. Подписи размещаются с учётом плотности данных и доступного пространства: анализируется наличие свободной области над и под каждым кластером, а также исключается перекрытие уже размещённых аннотаций. Благодаря этому даже в случаях с высокой плотностью разбиений сохраняется читаемость визуализации. Границы между кластерами представлены вертикальными линиями различного стиля — сплошными и пунктирными, в зависимости от типа разделения.

На рисунке @result-image представлен пример графической визуализации результатов анализа.
#figure(image("assets/result_image.png"),
    caption: "График интенсивностей с выделенными сегментами" 
) <result-image>

Помимо графика, формируется подробная таблица с характеристиками каждого кластера: включаются интервалы времени, агрегированные показатели интенсивности по направлениям, а также статистические диапазоны. Таблица построена с логической группировкой столбцов по типам данных, что облегчает восприятие и делает её пригодной как для отчётности, так и для анализа специалистами. Все численные значения форматируются для улучшения читаемости.

Пример такой таблицы приведён на рисунке @result-table.

#figure(image("assets/result_table.png"),
    caption: "Таблица со статистикой кластеров" 
) <result-table>

Для интеграции с веб-интерфейсом графики преобразуются в формат base64 без сохранения во временные файлы, что обеспечивает независимость от файловой системы и удобную передачу изображений через API. Табличный отчёт формируется в виде валидной HTML-разметки, готовой к встраиванию в интерфейс пользователя.

Проверка работоспособности модуля проводилась как на синтетических, так и на реальных данных, охватывая различные сценарии: от малых выборок с двумя кластерами до более сложных конфигураций с десятками сегментов и несколькими направлениями движения. Отдельное внимание уделялось корректности отображения границ, соответствию цветовой кодировки меткам кластеров и устойчивости визуализации при масштабировании данных.

Адаптивное размещение подписей прошло проверку в условиях плотной сегментации и сильных колебаний значений, что подтвердило его эффективность в сохранении читаемости графиков. Для таблиц проверялась целостность структуры, правильность формирования временных интервалов и корректность представления данных при изменении числа направлений.

Измерения производительности показали линейную масштабируемость алгоритмов относительно объёма входных данных. Модуль успешно прошёл интеграционное тестирование: выходные форматы корректно обрабатываются другими компонентами системы, изображения стабильно передаются через API, а HTML-таблицы без ошибок встраиваются в пользовательский интерфейс.

Результаты подтвердили соответствие модуля требованиям проекта и его готовность к эксплуатации в составе системы анализа транспортных временных рядов.

=== Комплексная оценка разработанной системы

В результате выполненной работы была создана полнофункциональная система анализа временных данных транспортной интенсивности, объединяющая современные технологии веб-разработки, серверной обработки данных и алгоритмов машинного обучения. Система демонстрирует высокую степень интеграции между компонентами и обеспечивает решение поставленных задач сегментации временных рядов с применением генетических алгоритмов.

Архитектурные решения, основанные на разделении клиентской и серверной частей, позволили создать масштабируемое и поддерживаемое решение. Веб-интерфейс, реализованный на чистых веб-технологиях без использования сторонних фреймворков, обеспечивает интуитивно понятное пошаговое взаимодействие с системой. Асинхронная обработка данных на серверной стороне гарантирует отзывчивость интерфейса даже при работе с большими объёмами информации.

Модуль обработки входных данных успешно справляется с различными форматами файлов — от стандартных CSV до сложноструктурированных PDF-документов. Автоматическое извлечение табличных данных из PDF с помощью библиотеки Camelot существенно расширяет применимость системы в условиях разнообразных источников данных. Реализованные механизмы очистки, интерполяции и структурирования данных обеспечивают высокое качество входной информации для последующего анализа.

Центральный аналитический модуль, построенный на основе генетического алгоритма, продемонстрировал высокую эффективность в задачах оптимального разбиения временных рядов на сегменты. Многокритериальная функция оценки, учитывающая различия между сегментами, равномерность их размеров и внутреннюю однородность, позволяет получать стабильные и воспроизводимые результаты. Дополнительная иерархическая кластеризация обеспечивает объединение схожих сегментов, что повышает интерпретируемость результатов анализа.

Модуль формирования отчётных данных создаёт наглядные визуализации и структурированные табличные отчёты, адаптированные для различных задач — от оперативного анализа до подготовки презентационных материалов. Адаптивное размещение аннотаций на графиках и логическая группировка данных в таблицах обеспечивают высокое качество представления результатов.

Комплексное тестирование системы подтвердило её надёжность, производительность и готовность к практическому применению. Все компоненты демонстрируют устойчивую работу как в изолированном режиме, так и в составе интегрированного решения. Система успешно обрабатывает реальные данные различного объёма и структуры, обеспечивая стабильные результаты анализа при времени обработки, приемлемом для практических задач.

Реализованная система полностью соответствует поставленным техническим требованиям и готова к развёртыванию в производственной среде для решения задач анализа транспортных потоков и других типов временных данных с аналогичной структурой.

= Технико-экономическое обоснование

Задачей данного дипломного проекта является разработка интеллектуальной системы прогнозирования и планирования интенсивности движения, предназначенной для автоматизированного анализа транспортных данных и формирования рекомендаций по светофорному регулированию на основе выявленных закономерностей в транспортных потоках. 

Разработка программного продукта предусматривает проведение практически всех стадий проектирования и относится ко второй группе сложности.

Последовательность расчетов:
- Расчёт объёма функций программного модуля;
- Расчёт полной себестоимости программного продукта;
- Расчёт цены и прибыли по программному продукту.

== Расчёт объёма функций программного модуля

Общий объём ПО определяется по формуле @V_0 исходя из объёма функций, реализуемых программой.

$
    V_0 = sum_(i=0)^(n) V_i
    text(",", font: "Times New Roman")
$ <V_0>

#indetless[где $V_0$ – общий объём ПО;]

$V_i$ – объём функций ПО;

$n$ – общее число функций.

В том случае, когда на стадии технико-экономического обоснования проекта невозможно рассчитать точный объём функций, то данный объём может быть получен на основании прогнозируемой оценки имеющихся фактических данных по аналогичным проектам, выполненным ранее, или применением нормативов по каталогу функций. 

По каталогу функций на основании функций разрабатываемого ПО определяется общий объём ПО. Также на основе зависимостей от организационных и технологических условий, был скорректирован объём на основе экспертных оценок. 

Уточнённый объём ПО ($V_y$) определяется по формуле @V_y.

$
    V_y = sum_(i=0)^(n) V_(y i)
    text(",", font: "Times New Roman")
$ <V_y>
#indetless[где	$V_(y i)$ – уточнённый объём отдельной функции в строках исходного кода.]

Перечень и объём функций ПО приведён в таблице @перечень_функций_ПО.

#figure(
  table(
    align: horizon,
    columns: (0.35fr, 1fr, 0.6fr, 0.6fr),
    cell(rowspan: 2, [№ \ функции]),
    cell(rowspan: 2, [Наименование (содержание) функции]),
    cell(colspan: 2, [Объём функции строк исходного кода]),
    [По каталогу $V_y$], [Уточнённый $V_(y i)$],
    [101], [Организация ввода информации], [130], [130],
    [104], [Обработка входного заказа и формирование таблиц], [630], [213],
    [303], [Обработка файлов], [1050], [280],
    [305], [Формирование файла], [2130], [15],
    [506], [Обработка ошибочных и сбойных ситуаций], [1540], [80],
    [507], [Обеспечение интерфейса между компонентами], [1680], [170],
    [701], [Математическая статистика и прогнозирование], [3780], [580],
    [702], [Расчет показателей], [420], [217],
    [707], [Графический вывод результатов], [420], [220],
  ),
  caption: "Перечень и объём функций программного обеспечения"
) <перечень_функций_ПО>

С учётом информации, указанной в таблице @перечень_функций_ПО, уточнённый объём ПО составил 1905 строк кода вместо предполагаемого количества 11780.

== Расчёт полной себестоимости программного модуля

Стоимостная оценка программного средства у разработчика предполагает составление сметы затрат, которая включает следующие статьи расходов:
- отчисления на социальные нужды ($Р_(с о ц)$);
- материалы и комплектующие изделия ($Р_м$);
- спецоборудование ($Р_с$);
- машинное время ($Р_(м в)$);
- расходы на научные командировки ($Р_(н к)$);
- прочие прямые расходы ($Р_(п р)$);
- накладные расходы ($Р_(н р)$);
- затраты на освоение и сопровождение программного средства ($Р_о$ и $Р_(с о)$).

Полная себестоимость ($С_п$) разработки программного продукта рассчитывается как сумма расходов по всем статьям с учётом рыночной стоимости аналогичных продуктов. 

Основной статьёй расходов на создание программного продукта является заработная плата проекта (основная и дополнительная) разработчиков (исполнителей) $(З П_(о с н)+ З П_(д о п))$, в число которых принято включать инженеров-программистов, руководителей проекта, системных архитекторов, дизайнеров, разработчиков баз данных, Web-мастеров и других специалистов, необходимых для решения специальных задач в команде. 

Расчёт заработной платы разработчиков программного продукта начинается с определения: 
- продолжительности времени разработки ($Ф_(р в)$), которое устанавливается студентом экспертным путём с учётом сложности, новизны программного обеспечения и фактически затраченного времени. В данном дипломном проекте $Ф_(р в)$  – 2 месяца; 
- количества разработчиков программного обеспечения. 

Заработная плата разработчиков определятся как сумма основной и дополнительной заработной платы всех исполнителей. 

Основная заработная плата каждого исполнителя определяется по формуле @ЗП_осн.
$
    З П_(о с н) = Т_(с т .1р) ⋅ Т_к / Ф_(э ф ф.р.в.) ⋅ Ф_(р в) ⋅ К_(п р)
    text(",", font: "Times New Roman")
$ <ЗП_осн>

#indetless[где $Т_(с т .1р)$ – базовая ставка 270 рублей, утверждённая согласно ЕТС РБ на дату написания дипломного проекта);]

$Т_к$ – тарифный коэффициент согласно разряду исполнителя;

$Ф_(э ф ф.р.в.)$ – среднее количество рабочих дней;

$Ф_(р в)$ – фонд рабочего времени исполнителя (продолжительность разработки программного модуля, дни);

$К_(п р)$ – коэффициент премии, $К_(п р) = 1,5$.

Рассчитаем основную заработную плату инженера-программиста и техника-программиста согласно формуле @ЗП_осн. Тарифный коэффициент согласно 11 разряду инженера-программиста $Т_к = 1,91$. Продолжительность разработки программного продукта – 44 дня. 

Дополнительная заработная плата каждого исполнителя ($Н_(д о п.з п.)$ – 20%). Она рассчитывается от основной заработной платы по формуле @ЗП_доп. 

$
    З П_(д о п) = З П_(о с н)  Н_(д о п.з п) / (100%)
    text(",", font: "Times New Roman")
$ <ЗП_доп>

Результаты вычислений внесём в таблицу @заработная_плата.

#figure(
  table(
    align: horizon,
    columns: (1.8fr, 0.7fr, 1fr, 1fr, 1fr, 1fr, 1.1fr, 1.1fr, 1.1fr),
    cell(rowspan: 2, rotate(-90deg, reflow: true)[Категория работников]), 
    cell(rowspan: 2, rotate(-90deg, reflow: true)[Разряд]), 
    cell(rowspan: 2, rotate(-90deg, reflow: true)[Тарифные коэффициент ($T_k$)]), 
    cell(rowspan: 2, rotate(-90deg, reflow: true)[$Ф_(э ф ф.р.в.)$, (дн.)]), 
    cell(rowspan: 2, rotate(-90deg, reflow: true)[Коэффициент премии ($K_p$)]),
    cell(rowspan: 2, rotate(-90deg, reflow: true)[$Т_к$ (час.)]),

    cell(colspan: 3, [Заработная плата, бел.руб.]), 

    rotate(-90deg, reflow: true)[Основная], 
    rotate(-90deg, reflow: true)[Дополнительная], 
    rotate(-90deg, reflow: true)[Всего],

    [Техник- \ программист], [11], [1.91], [44], [1.5], [8], [1547.1], [309.42], [1856.52],
    [Всего], [-], [-], [-], [-], [-], [1547.1], [309.42], [1856.52]
    
  ),
  caption: "Расчёт заработной платы"
) <заработная_плата>

Таким образом, как видно из таблицы, заработная плата инженера-программиста составляет 1856.52 бел. руб. 

Отчисления на социальные нужды ($Р_(с о ц)$) определяются по формуле @Р_соц в соответствии с действующим законодательством по нормативу (29% - отчисления в ФСЗН + 6% отчисления по обязательному страхованию): 

$
    Р_(с о ц) = (З П_(о с н) + З П_(д о п)) ⋅ 35 / 100
    text(",", font: "Times New Roman")
$ <Р_соц>

Расходы по статье «Cпецоборудование» ($Р_с$) включает затраты на приобретение технических и программных средств специального назначения, необходимых для разработки методического пособия, включая расходы на проектирование, изготовление, отладку и другое. 

В данном дипломном проекте для разработки интеллектуальной системы прогнозирования и планирования интенсивности движения приобретение какого-либо специализированного оборудования не предусматривалось. Так как спецоборудование не было приобретено, данная статья не рассчитывается.

По статье «Материалы и комплектующие изделия» ($Р_м$) отражаются расходы на бумагу, картридж и красящие ленты для принтера, необходимые для разработки ПП. Норма расхода материалов в суммарном выражении определяются в расчете на 100 строк исходного кода. В данном дипломном проекте не рассчитывается.

$Н_м$ – норма расхода материалов в расчете на 100 строк исходного кода программного продукта. Принимаем равной 0.4 бел. руб. 

По статье «Машинное время» ($Р_(м в)$) включают оплату машинного времени, необходимого для разработки и отладки программного продукта. Они определяются в машино-часах по нормативам на 100 строк исходного кода машинного времени. $Р_(м в)$  определяется по формуле @Р_мв.

$
    Р_(м в) = Ц_(м в i) ⋅ V_0 / 100 ⋅ Н_(м в)
    text(",", font: "Times New Roman")
$ <Р_мв>

#indetless[где	$Ц_(м в i)$  – цена одного машинного часа (50 бел. руб.);]

$V_0$ – уточнённый общий объём машинного кода. Согласно расчётам пункта @V_y данное значение равно 1905 строк;

$Н_(м в)$  – норматив расхода машинного времени на отладку 100 строк кода, машино-часов. Принимается в размере 0,6. 

Расходы по статье «Научные командировки» ($Р_(н к)$) берутся либо по смете научных командировок, разрабатываемой на предприятии, либо в процентах от основной заработной платы исполнителей (10-15%). Так как в данном проекте научные командировки не предусмотрены, данная статься не рассчитывается. 

Расходы по статье «Прочие затраты» ($Р_(п р)$) включают затраты на приобретение специальной научно-технической информации и специальной литературы. Определяются по нормативу в процентах к основной заработной плате исполнителей. Так как специальная научно-техническая информация и специальная литература не приобреталась, то данная статься не рассчитывается. 

Затраты по статье «Накладные расходы» ($Р_(н р)$) связаны с содержанием вспомогательных хозяйств, а также с расходами на общехозяйственные нужды. Определяется по нормативу в процентах к основной заработной плате по формуле @Р_нр.

$
    Р_(н р) = Н_(н р) / 100 ⋅ З П_(о с н)
    text(",", font: "Times New Roman")
$ <Р_нр>

#indetless[где	$Н_(н р)$ – норматив накладных расходов, в данном дипломном проекте норматив накладных расходов равен 40%.]

Сумма вышеперечисленных расходов по статься на программный продукт служит исходной базой для расчёта затрат на освоение и сопровождение программного продукта. Они рассчитываются по формуле @С_З.

$
    С З = З П_(о с н) + З П_(д о п) + Р_(с о ц) + Р_м + Р_(м в) + Р_с + Р_(н к) + Р_(п р) + Р_(н р)
    text(",", font: "Times New Roman")
$ <С_З>

Затраты на освоение программного продукта ($Р_о$). Организация-разработчик участвует в освоении программного продукта и несёт соответствующие затраты, на которые составляется смета, оплачиваемая заказчиком по договору. Затраты на освоение определяются по установленному нормативу от суммы затрат по формуле @Р_о.
$
    Р_о = С З ⋅ Н_о / 100
    text(",", font: "Times New Roman")
$ <Р_о>

#indetless[где	$С З$ – сумма вышеперечисленных расходов по статьям на разработку программного продукта;]

$Н_о$ – установленный норматив затрат на освоение. Для данного дипломного проекта принимается равной 5%.

Затраты на сопровождение программного продукта ($Р_(с о)$). Организация-разработчик осуществляет сопровождение программного продукта и несёт расходы, которые оплачиваются заказчиком в соответствии с договором и сметой на сопровождение. Эти расходы рассчитываются по формуле @Р_со.

$
    Р_(с о) = С З ⋅ Н_(с о) / 100
    text(",", font: "Times New Roman")
$ <Р_со>

#indetless[где	$С З$ – сумма вышеперечисленных расходов по статьям на разработку программного продукта;]

$Н_(с о)$ – установленный норматив затрат на сопровождение программного продукта. Для данного дипломного проекта принимается равной 5%. 

Полная себестоимость ($С П$) разработки программного продукта рассчитывается как сумма расходов по всем статьям. Она определяется по формуле @С_П.

$
    С П = С З + Р_о + Р_(с о)
    text(",", font: "Times New Roman")
$ <С_П>

Результаты вычислений занесём в таблицу @себестоимость_программного_продукта. 

#figure(
  table(
    align: horizon,
    columns: (3fr, 2fr, 2fr),
    [Наименование статей затрат],                         [Норматив, %],      [Сумма затрат, бел.руб.], 
    [Заработная плата],                                   [-],                [1856.52],
    [Основная заработная плата],                          [-],                [1547.1],
    [Дополнительная заработная плата],                    [-],                [309.42], 
    [Отчисления на социальные нужды],                     [35%],              [649.78],
    [Спецоборудование],                                   [Не применялось],   [-],
    [Материалы],                                          [Не применялись],   [-],
    [Машинное время],                                     [-],                [571.5],
    [Научные командировки],                               [Не планировались], [-],
    [Прочие затраты],                                     [Не применялись],   [-],
    [Накладные расходы],                                  [40%],              [618.84],
    [Сумма затрат на разработку \ программного продукта], [-],                [3696.64], 
    [Затраты на освоение],                                [5%],               [184.83],
    [Затраты на сопровождение],                           [5%],               [184.83],
    [Полная себестоимость],                               [-],                [4066.3],
  ),
  caption: "Себестоимость программного продукта."
) <себестоимость_программного_продукта>

В результате всех расчётов полная себестоимость программного продукта составила 4066,30 бел.руб.

== Расчёт цены и прибыли по программному продукту

Для определения цены программного продукта необходимо рассчитать плановую прибыль, которая рассчитывается по формуле @П. 

$
    П = С П ⋅ R / 100
    text(",", font: "Times New Roman")
$ <П>

#indetless[где	$С П$ – полная себестоимость программного модуля, бел. руб;]

$R$ – уровень рентабельности программного модуля. В данном дипломном проекте уровень рентабельности равен 30%.

После расчета прибыли от реализации по формуле @Ц_п определяется прогнозируемая цена программного продукта без налогов.

$
    Ц_п = С П + П
    text(",", font: "Times New Roman")
$ <Ц_п>

#indetless[где	$С П$ – полная себестоимость программного модуля управления ESP32 на базе JavaScript, бел. руб;]

$П$ – плановая прибыль от реализации программного модуля, бел. руб. 

Отпускная цена (цена реализации) программного продукта включает налог на добавленную стоимость и рассчитывается по формуле @Ц_о.

$
    Ц_о = С П + П + Н Д С_(п п)
    text(",", font: "Times New Roman")
$ <Ц_о>

#indetless[где	$С П$ – полная себестоимость программного модуля управления ESP32 на базе JavaScript, бел. руб;]

$П$ – плановая прибыль от реализации программного модуля, бел. руб.;

$Н Д С_(п п)$ – налог на добавленную стоимость.

Для данного программного продукта $Н Д С_(п п)$ рассчитывается по формуле @НДС_пп.

$
    Н Д С_(п п) = Ц_п ⋅ (Н Д С) / 100
    text(",", font: "Times New Roman")
$ <НДС_пп>

#indetless[где $Ц_п$ – прогнозируемая цена, бел. руб.;] 

$Н Д С$ – налог на добавленную стоимость. В настоящее время он составляет 20%.

Прибыль от реализации программного продукта за вычетом налога на прибыль является чистой прибылью ($П Ч$). Чистая прибыль остаётся организации-разработчику и представляет собой экономический эффект от создания нового программного продукта. Она рассчитывается по формуле @П_Ч.

$
    П Ч = П ⋅ (1 - Н_п / 100)
    text(",", font: "Times New Roman")
$ <П_Ч>

#indetless[где $П$ – плановая прибыль от реализации программного модуля, бел. руб.;] 

$Н_п$ – ставка налога на прибыль. В настоящее время он равен 20%.

Все расчёты цены и прибыли по программному продукту сведены в таблицу @расчёт_отпускной_цены.

#figure(
  table(
    align: horizon,
    columns: (3fr, 2fr, 3fr),
    [Наименование статей затрат], [Норматив, %], [Сумма затрат, бел. руб.],
    [Полная себестоимость],       [-],           [4066.3],
    [Прибыль],                    [30],          [1219.89],
    [Цена без НДС],               [-],           [5286.19],
    [НДС],                        [20],          [1057.24],
    [Отпускная цена],             [-],           [6343.43],
    [Налог на прибыль],           [20],          [243.98],
    [Чистая прибыль],             [-],           [975.91]
  ),
  caption: "Расчёт отпускной цены и чистой прибыли программного модуля"
) <расчёт_отпускной_цены>

В ходе произведенных расчетов определены основные экономические показатели: полная себестоимость – 4066.30 бел.руб.; прогнозируемая цена – 5286.19 бел. руб.; чистая прибыль – 975.91 бел.руб. 

Разработанная система имеет малое количество конкурентов с более высокими ценами на их услуги. Таким образом, рассчитанная отпускная цена на программный продукт, разрабатываемой в рамках данного дипломного проекта, является конкурентоспособной. При расчете цены учтены отчисления в фонд социальной защиты, а также налоги, необходимые к уплате. К конечному итогу получаем окончательную цену продукта, равную 6343.43 белорусских рубля.

= Энергосбережение

Вопрос энергосбережения становится всё более актуальным в условиях роста потребления ресурсов в городском хозяйстве и стремления к устойчивому развитию. Одной из сфер, где существует существенный потенциал для повышения энергоэффективности, является организация дорожного движения, в частности — работа светофорных объектов. Светофоры, особенно расположенные на крупных перекрёстках, работают круглосуточно и потребляют электрическую энергию как на управление сигналами, так и на обеспечение вспомогательных функций, включая питание контроллеров, модемов, датчиков и подсветки.

На первый взгляд энергопотребление одного светофорного объекта может показаться незначительным, однако в масштабах города, где количество регулируемых перекрёстков может исчисляться сотнями, общее энергопотребление становится весьма ощутимым. Более того, неэффективные режимы работы светофоров могут приводить к косвенным энергетическим потерям: увеличению времени простоя транспортных средств с работающими двигателями, частым остановкам и ускорениям, росту расхода топлива и, как следствие, снижению общей энергоэффективности транспортной системы.

Одним из путей снижения прямого и косвенного энергопотребления является рационализация режимов светофорного регулирования. Если распределение фаз и длительность циклов светофора не соответствуют текущей или характерной для определённого времени суток интенсивности движения, это приводит к ненужным задержкам и снижению пропускной способности, заставляя транспортные средства расходовать больше топлива. Кроме того, чрезмерно длинные зелёные фазы при отсутствии потока или, наоборот, частая смена сигналов в часы с высокой нагрузкой создают неэффективные условия для проезда перекрёстка и увеличивают число остановок.

Для достижения энергосбережения необходимо обеспечить согласованность работы светофорных объектов с реальными транспортными потоками. В этом контексте современные интеллектуальные системы, способные автоматически анализировать исторические данные и выявлять закономерности в трафике, становятся эффективным инструментом планирования. Они позволяют точно настраивать режимы работы светофоров в зависимости от времени суток, дня недели и уровня загруженности, минимизируя как ненужное электропотребление самих объектов, так и косвенные потери, связанные с простоем и неравномерным движением транспорта.

Предлагаемая интеллектуальная система прогнозирования и планирования интенсивности движения ориентирована в том числе на достижение целей энергосбережения за счёт повышения эффективности работы светофорных объектов. Анализируя временные ряды транспортной активности, система способна автоматически выявлять периоды, в течение которых отдельные направления движения характеризуются низкой интенсивностью. В таких случаях она предлагает сократить длительность зелёных фаз, тем самым уменьшая общее время включения сигнальных ламп и снижая прямое энергопотребление оборудования.

Кроме того, система формирует интервалы с устойчивыми характеристиками потока, что позволяет избежать излишне частых переключений режимов и, как следствие, уменьшить нагрузку на контроллеры и снизить энергозатраты, связанные с их работой. Более точная настройка фаз светофора в соответствии с реальной загруженностью позволяет сократить число ненужных остановок и запусков транспортных средств, что в свою очередь снижает расход топлива и связанные с ним энергетические потери. Особенно заметный эффект достигается в ночные и малонагруженные часы, когда система может предложить более длительные и стабильные интервалы работы светофоров, исключающие лишние циклы мигания и переходов, тем самым снижая нагрузку на оборудование.

Таким образом, применение разработанной интеллектуальной системы в городских условиях, где ещё не внедрены адаптивные светофорные комплексы, обеспечивает существенное повышение энергоэффективности. За счёт автоматизированного анализа данных и обоснованного планирования режимов светофорного регулирования система позволяет минимизировать избыточное энергопотребление и внести вклад в устойчивое развитие транспортной инфраструктуры.

#numless[= Заключение]

В ходе выполнения дипломного проекта была рассмотрена актуальная задача повышения эффективности работы регулируемых перекрёстков в условиях городской транспортной сети. Изучение предметной области показало, что традиционные методы светофорного регулирования, основанные на ручной настройке режимов, обладают существенными недостатками — высокой трудоёмкостью, зависимостью от субъективных оценок и низкой гибкостью при изменении транспортной ситуации.

Для решения поставленной цели была разработана интеллектуальная система прогнозирования и планирования интенсивности движения, которая автоматизирует процесс анализа исторических данных о транспортных потоках. Система обеспечивает автоматическое выделение временных интервалов с различной загруженностью и формирование рекомендаций по режимам работы светофоров. Пользователь получает наглядную карту времени с визуализацией смены нагрузки в течение суток и сводные статистические данные для проектирования и оптимизации светофорных циклов.

Результаты работы продемонстрировали возможность значительного повышения эффективности планирования в области организации дорожного движения. Применение разработанной системы позволяет сократить влияние человеческого фактора и повысить масштабируемость процесса на большое количество перекрёстков. За счёт точного соответствия режимов реальной интенсивности движения достигается сокращение времени ожидания участников движения и снижение энергопотребления светофорных объектов.

Созданная интеллектуальная система может быть успешно применена в качестве эффективного инструмента поддержки принятия решений. Её внедрение способно повысить общую эффективность функционирования улично-дорожной сети, сократить заторы и задержки, а также внести вклад в энергосбережение и устойчивое развитие транспортной инфраструктуры.

#numless[= Список использованных сокращений]

SCOOT -- Split Cycle Offset Optimization Technique.

SCATS -- Sydney Coordinated Adaptive Traffic System.

DBSCAN -- Density-Based Spatial Clustering of Applications with Noise.

GMM -- Gaussian Mixture Model.

EM -- Expectation-Maximization.

PMM -- Poisson Mixture Model.

FINCH -- Fast and INterpretable Clustering of High-dimensional data.

TW-FINCH -- Time Windowed FINCH.

ClaSP -- Closed Sequential Patterns algorithm.

Ptr-Net -- Pointer Network.

KernelCPD -- Kernel Change Point Detection.

WSS -- Window Sliding Segmentation.

PELT -- Pruned Exact Linear Time.

AIC -- Akaike Information Criterion.

BIC -- Bayesian Information Criterion.

REST -- Representational State Transfer.

API -- Application Programming Interface.

HTML -- HyperText Markup Language.

CSS -- Cascading Style Sheets.

WSGI -- Web Server Gateway Interface.

ASGI -- Asynchronous Server Gateway Interface.

HTTP -- Hypertext Transfer Protocol.

CSV -- Comma-Separated Values.

PDF -- Portable Document Format.

JSON -- JavaScript Object Notation.

DEAP -- Distributed Evolutionary Algorithms in Python.

ПО -- программное обеспечение.

#bibliography("utils/referencies.bib")

#set page(background: none)
#numless[= Приложение А. Код программы]

// TODO нормоконтроль, оформление

